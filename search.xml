<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Github]]></title>
    <url>%2F2019%2F07%2F07%2FStart%2F</url>
    <content type="text"><![CDATA[Blog搭建准备环境 node &amp;&amp; git brew install nodenpm : brew install npmgit : brew install git 验证: node –versionnpm –versiongit –version 安装Hexo npm install -g hexo-cli 初始化Hexo hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 新建完成后，在路径下，会产生这些文件和文件夹： 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 注： hexo相关命令均在站点目录下，用Git Bash运行。 站点配置文件：站点目录下的_config.yml。路径为&lt;folder&gt;_config.yml 主题配置文件：站点目录下的themes文件夹下的，主题文件夹下的_config.yml。路径为\themes&lt;主题文件夹&gt;_config.yml 启动服务器。在路径下，命令行（即Git Bash）输入以下命令，运行即可： hexo server 浏览器访问网址： http://localhost:4000/ 至此，您的Hexo博客已经搭建在本地。 部署 GithubPages1.创建Github账号2.创建仓库， 仓库名为：&lt;Github账号名称&gt;.github.io3.将本地Hexo博客推送到GithubPages3.1 安装hexo-deployer-git插件。在命令行（即Git Bash）运行以下命令即可： npm install hexo-deployer-git –save 3.2. 添加SSH key。创建一个 SSH key 。在命令行（即Git Bash）输入以下命令， 回车三下即可： ssh-keygen -t rsa -C “邮箱地址” 添加到 github。 复制密钥文件内容（路径形如～～.ssh\id_rsa.pub），粘贴到https://github.com/settings/keys即可。 测试是否添加成功。在命令行（即Git Bash）依次输入以下命令，返回“You’ve successfully authenticated”即成功： ssh -T git@github.com 3.3. 修改_config.yml（在站点目录下）。文件末尾修改为：123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:&lt;Github账号名称&gt;/&lt;Github账号名称&gt;.github.io.git branch: master 注意：上面仓库地址写ssh地址，不写http地址。每个冒号后面都是有一个空格的，这是node的语法。 3.4. 推送到GithubPages。在命令行（即Git Bash）依次输入以下命令， 返回INFO Deploy done: git即成功推送： hexo g -d 3.5 等待1分钟左右，浏览器访问网址https://&lt;Github账号名称&gt;.github.io 至此，您的Hexo博客已经搭建在GithubPages, 域名为https://&lt;Github账号名称&gt;.github.io。 Blog美化https://github.com/theme-next/hexo-theme-nexthttp://theme-next.iissnan.com/getting-started.html 参考：https://zhuanlan.zhihu.com/p/69684798https://www.simon96.online/2018/10/12/hexo-tutorial/ Themes：https://github.com/Doublemine/hexo-theme-next]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>Testing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive高级函数：窗口函数、分析函数、增强group]]></title>
    <url>%2F2019%2F07%2F07%2FHive%2Fover%2F</url>
    <content type="text"><![CDATA[窗口函数与分析函数应用场景:（1）用于分区排序（2）动态Group By（3）Top N（4）累计计算（5）层次查询 窗口函数 函数 功能 FIRST_VALUE 取分组内排序后，截止到当前行，第一个值 LAST_VALUE 取分组内排序后，截止到当前行，最后一个值 LEAD(col,n,DEFAULT) 用于统计窗口内往下第n行值。第一个参数为列名，第二个参数为往下第n行（可选，默认为1），第三个参数为默认值（当往下第n行为NULL时候，取默认值，如不指定，则为NULL） LAG(col,n,DEFAULT) 与lead相反，用于统计窗口内往上第n行值。第一个参数为列名，第二个参数为往上第n行（可选，默认为1），第三个参数为默认值（当往上第n行为NULL时候，取默认值，如不指定，则为NULL） OVER从句 1、使用标准的聚合函数COUNT、SUM、MIN、MAX、AVG2、使用PARTITION BY语句，使用一个或者多个原始数据类型的列3、使用PARTITION BY与ORDER BY语句，使用一个或者多个数据类型的分区或者排序列4、使用窗口规范，窗口规范支持以下格式： 1(ROWS | RANGE) BETWEEN (UNBOUNDED | [num]) PRECEDING AND ([num] PRECEDING | CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING) 1(ROWS | RANGE) BETWEEN CURRENT ROW AND (CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING) 1(ROWS | RANGE) BETWEEN [num] FOLLOWING AND (UNBOUNDED | [num]) FOLLOWING 当ORDER BY后面缺少窗口从句条件，窗口规范默认是 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW. 当ORDER BY和窗口从句都缺失, 窗口规范默认是 ROW BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING. OVER从句支持以下函数， 但是并不支持和窗口一起使用它们。Ranking函数: Rank, NTile, DenseRank, CumeDist, PercentRank.Lead 和 Lag 函数. 分析函数 ROW_NUMBER() 从1开始，按照顺序，生成分组内记录的序列,比如，按照pv降序排列，生成分组内每天的pv名次,ROW_NUMBER()的应用场景非常多，再比如，获取分组内排序第一的记录;获取一个session中的第一条refer等。 RANK() 生成数据项在分组中的排名，排名相等会在名次中留下空位 DENSE_RANK() 生成数据项在分组中的排名，排名相等会在名次中不会留下空位 CUME_DIST 小于等于当前值的行数/分组内总行数。比如，统计小于等于当前薪水的人数，所占总人数的比例 PERCENT_RANK 分组内当前行的RANK值-1/分组内总行数-1 NTILE(n) 用于将分组数据按照顺序切分成n片，返回当前切片值，如果切片不均匀，默认增加第一个切片的分布。NTILE不支持ROWS BETWEEN，比如 NTILE(2) OVER(PARTITION BY cookieid ORDER BY createtime ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) Hive2.1.0及以后支持Distinct 在聚合函数（SUM, COUNT and AVG）中，支持distinct，但是在ORDER BY 或者 窗口限制不支持。 1COUNT(DISTINCT a) OVER (PARTITION BY c)1 Hive 2.2.0中在使用ORDER BY和窗口限制时支持distinct 1COUNT(DISTINCT a) OVER (PARTITION BY c ORDER BY d ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)1 Hive2.1.0及以后支持在OVER从句中支持聚合函数 123SELECT rank() OVER (ORDER BY sum(b))FROM TGROUP BY a;123 用例测试数据集： user_id device_id user_type amount sex sales log_time u_001 d_001 new 60 man 9 2019-07-01 u_002 d_001 old 40 women 6 2019-07-03 u_003 d_001 new 80 man 5 2019-07-04 u_004 d_001 new 50 man 4 2019-07-05 u_005 d_001 new 30 man 7 2019-07-07 u_006 d_002 old 70 women 10 2019-07-02 u_007 d_002 old 90 man 2 2019-07-03 u_008 d_002 new 10 women 1 2019-07-04 u_009 d_002 new 20 women 3 2019-07-06 u_010 d_002 new 100 women 8 2019-07-17 COUNT、SUM、MIN、MAX、AVGrows12345678910111213141516171819202122select user_id, user_type, sales, --默认为从起点到当前行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc) AS sales_1, --从起点到当前行，结果与sales_1相同（若排序字段有重复值则回出现不同，不稳定排序）。 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS sales_2, --当前行+往前3行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS sales_3, --当前行+往前3行+往后1行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING) AS sales_4, --当前行+往后所有行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS sales_5, --分组内所有行 SUM(sales) OVER(PARTITION BY user_type) AS sales_6 from order_detailorder by user_type, sales, user_id 结果： user_id user_type sales sales_1 sales_2 sales_3 sales_4 sales_5 sales_6 u_008 new 1 1 1 1 4 37 37 u_009 new 3 4 4 4 8 36 37 u_004 new 4 8 8 8 13 33 37 u_003 new 5 13 13 13 20 29 37 u_005 new 7 20 20 19 27 24 37 u_010 new 8 28 28 24 33 17 37 u_001 new 9 37 37 29 29 9 37 u_007 old 2 2 2 2 8 18 18 u_002 old 6 8 8 8 18 16 18 u_006 old 10 18 18 18 18 10 18 注意:结果和ORDER BY相关,默认为升序如果不指定ROWS BETWEEN,默认为从起点到当前行;如果不指定ORDER BY，则将分组内所有值累加; 关键是理解ROWS BETWEEN含义,也叫做WINDOW子句：PRECEDING：往前FOLLOWING：往后CURRENT ROW：当前行UNBOUNDED：无界限（起点或终点）UNBOUNDED PRECEDING：表示从前面的起点UNBOUNDED FOLLOWING：表示到后面的终点其他COUNT、AVG，MIN，MAX，和SUM用法一样。 max()函数无论有没有order by 都是计算整个分区的最大值 更多可参考Oracle 数据库的分析语法 理解：执行逻辑为先partiton 内order by 然后sum/max/min 1234567891011121314151617181920212223242526272829参考：https://dacoolbaby.iteye.com/blog/1960373在Hive里面，可以把这一部分独立抽出来做声明。如：select user_id, user_type, sales, log_time, sum(sales) over w1 as s, min(sales) over w1 as mi, max(sales) over w1 as ma, avg(sales) over w1 as agfrom app.order_detail window w1 as(distribute by user_type sort by sales asc rows between 2 preceding and 2 following) ; 其中的window w1 则是抽出声明的窗口部分。如果在一条Hive SQL涉及到多个窗口函数的引用呢？select user_id, user_type, sales, log_time, sum(sales) over w1 as s1, sum(sales) over w2 as s2from app.order_detail window w1 as(distribute by user_type sort by sales asc rows between 2 preceding and 2 following), w2 as(distribute by user_type sort by sales asc rows between unbounded preceding and current row) ; range12345678910参考：https://stackoverflow.com/questions/30809097/sum-over-a-date-range-per-group-in-hiveselect user_id, user_type, sales, log_time, sum(sales) OVER( PARTITION BY user_type ORDER BY unix_timestamp(log_time, 'yyyy-MM-dd') ASC RANGE BETWEEN 86400 PRECEDING and CURRENT ROW) as countfrom app.order_detail 结果： user_id user_type sales log_time count u_001 new 9 2019-07-01 9 u_008 new 1 2019-07-04 6 u_003 new 5 2019-07-04 6 u_004 new 4 2019-07-05 10 u_009 new 3 2019-07-06 7 u_005 new 7 2019-07-07 10 u_010 new 8 2019-07-17 8 u_006 old 10 2019-07-02 10 u_007 old 2 2019-07-03 18 u_002 old 6 2019-07-03 18 理解：当前时间往上三天的累积数量 86400=3600*24 （一天） first_value与last_value12345678910select user_id, user_type, ROW_NUMBER() OVER(PARTITION BY user_type ORDER BY sales) AS row_num, first_value(user_id) over (partition by user_type order by sales desc) as max_sales_user, first_value(user_id) over (partition by user_type order by sales asc) as min_sales_user, last_value(user_id) over (partition by user_type order by sales desc) as curr_last_min_user, last_value(user_id) over (partition by user_type order by sales asc) as curr_last_max_userfrom order_detail; 结果： user_id user_type row_num max_sales_user min_sales_user curr_last_min_user curr_last_max_user u_001 new 7 u_001 u_008 u_001 u_001 u_010 new 6 u_001 u_008 u_010 u_010 u_005 new 5 u_001 u_008 u_005 u_005 u_003 new 4 u_001 u_008 u_003 u_003 u_004 new 3 u_001 u_008 u_004 u_004 u_009 new 2 u_001 u_008 u_009 u_009 u_008 new 1 u_001 u_008 u_008 u_008 u_006 old 3 u_006 u_007 u_006 u_006 u_002 old 2 u_006 u_007 u_002 u_002 u_007 old 1 u_006 u_007 u_007 u_007 lead与lag12345678select user_id,device_id, lead(device_id) over (order by sales) as default_after_one_line, lag(device_id) over (order by sales) as default_before_one_line, lead(device_id,2) over (order by sales) as after_two_line, lag(device_id,2,'abc') over (order by sales) as before_two_linefrom order_detail; RANK、ROW_NUMBER、DENSE_RANK1234567select user_id,user_type,sales, RANK() over (partition by user_type order by sales desc) as rank, ROW_NUMBER() over (partition by user_type order by sales desc) as row_number, DENSE_RANK() over (partition by user_type order by sales desc) as desc_rankfrom order_detail; user_id user_type sales log_time rank desc_rank row_number u_010 new 8 2019-07-17 1 1 1 u_005 new 7 2019-07-07 2 2 2 u_009 new 3 2019-07-06 3 3 3 u_004 new 4 2019-07-05 4 4 4 u_008 new 1 2019-07-04 5 5 5 u_003 new 5 2019-07-04 5 5 6 u_001 new 9 2019-07-01 7 6 7 u_007 old 2 2019-07-03 1 1 1 u_002 old 6 2019-07-03 1 1 2 u_006 old 10 2019-07-02 3 2 3 NTILE123456789101112131415select user_type,sales, --分组内将数据分成2片 NTILE(2) OVER(PARTITION BY user_type ORDER BY sales) AS nt2, --分组内将数据分成3片 NTILE(3) OVER(PARTITION BY user_type ORDER BY sales) AS nt3, --分组内将数据分成4片 NTILE(4) OVER(PARTITION BY user_type ORDER BY sales) AS nt4, --将所有数据分成4片 NTILE(4) OVER(ORDER BY sales) AS all_nt4from order_detailorder by user_type, sales user_type sales nt2 nt3 nt4 all_nt4 new 1 1 1 1 1 new 3 1 1 1 1 new 4 1 1 2 2 new 5 1 2 2 2 new 7 2 2 3 3 new 8 2 3 3 3 new 9 2 3 4 4 old 2 1 1 1 1 old 6 1 2 2 2 old 10 2 3 3 4 求取sale前20%的用户ID1234567891011select user_idfrom( select user_id, NTILE(5) OVER(ORDER BY sales desc) AS nt from order_detail)Awhere nt=1; CUME_DIST、PERCENT_RANK12345678select user_id,user_type,sales,--没有partition,所有数据均为1组CUME_DIST() OVER(ORDER BY sales) AS cd1,--按照user_type进行分组CUME_DIST() OVER(PARTITION BY user_type ORDER BY sales) AS cd2 from order_detail; user_id user_type sales cd1 cd2 u_008 new 1 0.1 0.14285714285714285 u_009 new 3 0.3 0.2857142857142857 u_004 new 4 0.4 0.42857142857142855 u_003 new 5 0.5 0.5714285714285714 u_005 new 7 0.7 0.7142857142857143 u_010 new 8 0.8 0.8571428571428571 u_001 new 9 0.9 1.0 u_007 old 2 0.2 0.3333333333333333 u_002 old 6 0.6 0.6666666666666666 u_006 old 10 1.0 1.0 1234567891011select user_type,sales,--分组内总行数 SUM(1) OVER(PARTITION BY user_type) AS s, --RANK值 RANK() OVER(ORDER BY sales) AS r, PERCENT_RANK() OVER(ORDER BY sales) AS pr,--分组内 PERCENT_RANK() OVER(PARTITION BY user_type ORDER BY sales) AS prg from order_detail; user_type sales s r pr prg new 1 7 1 0.0 0.0 new 3 7 3 0.2222222222222222 0.16666666666666666 new 4 7 4 0.3333333333333333 0.3333333333333333 new 5 7 5 0.4444444444444444 0.5 new 7 7 7 0.6666666666666666 0.6666666666666666 new 8 7 8 0.7777777777777778 0.8333333333333334 new 9 7 9 0.8888888888888888 1.0 old 2 3 2 0.1111111111111111 0.0 old 6 3 6 0.5555555555555556 0.5 old 10 3 10 1.0 1.0 增强的聚合 Cube和Grouping 和Rollup这几个分析函数通常用于OLAP中，不能累加，而且需要根据不同维度上钻和下钻的指标统计，比如，分小时、天、月的UV数。 GROUPING SETS在一个GROUP BY查询中，根据不同的维度组合进行聚合，等价于将不同维度的GROUP BY结果集进行UNION ALL,其中的GROUPING__ID，表示结果属于哪一个分组集合。 12345678910111213141516171819202122232425select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesGROUPING SETS(user_type,sales) ORDER BY GROUPING__ID;select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesGROUPING SETS(user_type,sales,(user_type,sales)) ORDER BY GROUPING__ID; CUBE根据GROUP BY的维度的所有组合进行聚合。 123456789101112select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesWITH CUBE ORDER BY GROUPING__ID; user_type log_time pv grouping__id NULL NULL 10 0 NULL 2019-07-01 1 2 NULL 2019-07-02 1 2 NULL 2019-07-03 2 2 NULL 2019-07-04 2 2 NULL 2019-07-05 1 2 NULL 2019-07-06 1 2 NULL 2019-07-07 1 2 NULL 2019-07-17 1 2 new NULL 7 1 new 2019-07-01 1 3 new 2019-07-04 2 3 new 2019-07-05 1 3 new 2019-07-06 1 3 new 2019-07-07 1 3 new 2019-07-17 1 3 old NULL 3 1 old 2019-07-02 1 3 old 2019-07-03 2 3 ROLLUP是CUBE的子集，以最左侧的维度为主，从该维度进行层级聚合。 123456789101112select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesWITH ROLLUP ORDER BY GROUPING__ID; 题： 设备总共使用天数和最早、最晚使用的用户和时间 设备连续使用最长的天数 前三天的销售额，后三天的销售额？ 每5分钟统计前一小时的在线人数 参考： https://blog.csdn.net/scgaliguodong123_/article/details/60881166 https://blog.csdn.net/scgaliguodong123_/article/details/60135385 https://dacoolbaby.iteye.com/blog/1960373 https://stackoverflow.com/questions/30809097/sum-over-a-date-range-per-group-in-hive https://blog.csdn.net/Abysscarry/article/details/81408265 http://lxw1234.com/archives/2015/07/367.htm https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
</search>
