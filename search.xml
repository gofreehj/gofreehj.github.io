<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hive SQL 的编译过程]]></title>
    <url>%2F2019%2F07%2F12%2FHive%2FHive%20SQL%20%E7%9A%84%E7%BC%96%E8%AF%91%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[原文地址 https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html Hive 是基于 Hadoop 的一个数据仓库系统，在各大公司都有广泛的应用。美团数据仓库也是基于 Hive 搭建，每天执行近万次的 Hive ETL 计算流程，负责每天数百 GB 的数据存储和分析。Hive 的稳定性和性能对我们的数据分析非常关键。 在几次升级 Hive 的过程中，我们遇到了一些大大小小的问题。通过向社区的咨询和自己的努力，在解决这些问题的同时我们对 Hive 将 SQL 编译为 MapReduce 的过程有了比较深入的理解。对这一过程的理解不仅帮助我们解决了一些 Hive 的 bug，也有利于我们优化 Hive SQL，提升我们对 Hive 的掌控力，同时有能力去定制一些需要的功能。 MapReduce 实现基本 SQL 操作的原理详细讲解 SQL 编译为 MapReduce 之前，我们先来看看 MapReduce 框架实现 SQL 基本操作的原理 Join 的实现原理1select u.name, o.orderid from order o join user u on o.uid = u.uid; 在 map 的输出 value 中为不同表的数据打上 tag 标记，在 reduce 阶段根据 tag 判断数据来源。MapReduce 的过程如下（这里只是说明最基本的 Join 的实现，还有其他的实现方式） MapReduce CommonJoin 的实现 Group By 的实现原理1select rank, isonline, count(*) from city group by rank, isonline; 将 GroupBy 的字段组合为 map 的输出 key 值，利用 MapReduce 的排序，在 reduce 阶段保存 LastKey 区分不同的 key。MapReduce 的过程如下（当然这里只是说明 Reduce 端的非 Hash 聚合过程） MapReduce Group By 的实现 Distinct 的实现原理1select dealid, count(distinct uid) num from order group by dealid; 当只有一个 distinct 字段时，如果不考虑 Map 阶段的 Hash GroupBy，只需要将 GroupBy 字段和 Distinct 字段组合为 map 输出 key，利用 mapreduce 的排序，同时将 GroupBy 字段作为 reduce 的 key，在 reduce 阶段保存 LastKey 即可完成去重 MapReduce Distinct 的实现 如果有多个 distinct 字段呢，如下面的 SQL 1select dealid, count(distinct uid), count(distinct date) from order group by dealid; 实现方式有两种： （1）如果仍然按照上面一个 distinct 字段的方法，即下图这种实现方式，无法跟据 uid 和 date 分别排序，也就无法通过 LastKey 去重，仍然需要在 reduce 阶段在内存中通过 Hash 去重 MapReduce Multi Distinct 的实现 （2）第二种实现方式，可以对所有的 distinct 字段编号，每行数据生成 n 行数据，那么相同字段就会分别排序，这时只需要在 reduce 阶段记录 LastKey 即可去重。 这种实现方式很好的利用了 MapReduce 的排序，节省了 reduce 阶段去重的内存消耗，但是缺点是增加了 shuffle 的数据量。 需要注意的是，在生成 reduce value 时，除第一个 distinct 字段所在行需要保留 value 值，其余 distinct 数据行 value 字段均可为空。 MapReduce Multi Distinct 的实现 SQL 转化为 MapReduce 的过程了解了 MapReduce 实现 SQL 基本操作之后，我们来看看 Hive 是如何将 SQL 转化为 MapReduce 任务的，整个编译过程分为六个阶段： Antlr 定义 SQL 的语法规则，完成 SQL 词法，语法解析，将 SQL 转化为抽象语法树 AST Tree 遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock 遍历 QueryBlock，翻译为执行操作树 OperatorTree 逻辑层优化器进行 OperatorTree 变换，合并不必要的 ReduceSinkOperator，减少 shuffle 数据量 遍历 OperatorTree，翻译为 MapReduce 任务 物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划 下面分别对这六个阶段进行介绍 Phase1 SQL 词法，语法解析AntlrHive 使用 Antlr 实现 SQL 的词法和语法解析。Antlr 是一种语言识别的工具，可以用来构造领域语言。 这里不详细介绍 Antlr，只需要了解使用 Antlr 构造特定的语言只需要编写一个语法文件，定义词法和语法替换规则即可，Antlr 完成了词法分析、语法分析、语义分析、中间代码生成的过程。 Hive 中语法规则的定义文件在 0.10 版本以前是 Hive.g 一个文件，随着语法规则越来越复杂，由语法规则生成的 Java 解析类可能超过 Java 类文件的最大上限，0.11 版本将 Hive.g 拆成了 5 个文件，词法规则 HiveLexer.g 和语法规则的 4 个文件 SelectClauseParser.g，FromClauseParser.g，IdentifiersParser.g，HiveParser.g。 抽象语法树 AST Tree经过词法和语法解析后，如果需要对表达式做进一步的处理，使用 Antlr 的抽象语法树语法 Abstract Syntax Tree，在语法分析的同时将输入语句转换成抽象语法树，后续在遍历语法树时完成进一步的处理。 下面的一段语法是 Hive SQL 中 SelectStatement 的语法规则，从中可以看出，SelectStatement 包含 select, from, where, groupby, having, orderby 等子句。 （在下面的语法规则中，箭头表示对于原语句的改写，改写后会加入一些特殊词标示特定语法，比如 TOK_QUERY 标示一个查询块） 123456789101112131415selectStatement : selectClause fromClause whereClause? groupByClause? havingClause? orderByClause? clusterByClause? distributeByClause? sortByClause? limitClause? -&gt; ^(TOK_QUERY fromClause ^(TOK_INSERT ^(TOK_DESTINATION ^(TOK_DIR TOK_TMP_FILE)) selectClause whereClause? groupByClause? havingClause? orderByClause? clusterByClause? distributeByClause? sortByClause? limitClause?)) ; 样例 SQL为了详细说明 SQL 翻译为 MapReduce 的过程，这里以一条简单的 SQL 为例，SQL 中包含一个子查询，最终将数据写入到一张表中 123456789101112131415161718FROM( SELECT p.datekey datekey, p.userid userid, c.clienttype FROM detail.usersequence_client c JOIN fact.orderpayment p ON p.orderid = c.orderid JOIN default.user du ON du.userid = p.userid WHERE p.datekey = 20131118 ) baseINSERT OVERWRITE TABLE `test`.`customer_kpi`SELECT base.datekey, base.clienttype, count(distinct base.userid) buyer_countGROUP BY base.datekey, base.clienttype SQL 生成 AST TreeAntlr 对 Hive SQL 解析的代码如下，HiveLexerX，HiveParser 分别是 Antlr 对语法文件 Hive.g 编译后自动生成的词法解析和语法解析类，在这两个类中进行复杂的解析。 1234567891011121314HiveLexerX lexer = new HiveLexerX(new ANTLRNoCaseStringStream(command)); TokenRewriteStream tokens = new TokenRewriteStream(lexer);if (ctx != null) &#123; ctx.setTokenRewriteStream(tokens);&#125;HiveParser parser = new HiveParser(tokens); parser.setTreeAdaptor(adaptor);HiveParser.statement_return r = null;try &#123; r = parser.statement(); &#125; catch (RecognitionException e) &#123; e.printStackTrace(); throw new ParseException(parser.errors);&#125; 最终生成的 AST Tree 如下图右侧（使用 Antlr Works 生成，Antlr Works 是 Antlr 提供的编写语法文件的编辑器），图中只是展开了骨架的几个节点，没有完全展开。 子查询 1/2，分别对应右侧第 1/2 两个部分。 SQL 生成 AST Tree 这里注意一下内层子查询也会生成一个 TOK_DESTINATION 节点。请看上面 SelectStatement 的语法规则，这个节点是在语法改写中特意增加了的一个节点。原因是 Hive 中所有查询的数据均会保存在 HDFS 临时的文件中，无论是中间的子查询还是查询最终的结果，Insert 语句最终会将数据写入表所在的 HDFS 目录下。 详细来看，将内存子查询的 from 子句展开后，得到如下 AST Tree，每个表生成一个 TOK_TABREF 节点，Join 条件生成一个 “=” 节点。其他 SQL 部分类似，不一一详述。 AST Tree Phase2 SQL 基本组成单元 QueryBlockAST Tree 仍然非常复杂，不够结构化，不方便直接翻译为 MapReduce 程序，AST Tree 转化为 QueryBlock 就是将 SQL 进一部抽象和结构化。 QueryBlockQueryBlock 是一条 SQL 最基本的组成单元，包括三个部分：输入源，计算过程，输出。简单来讲一个 QueryBlock 就是一个子查询。 下图为 Hive 中 QueryBlock 相关对象的类图，解释图中几个重要的属性 QB#aliasToSubq（表示 QB 类的 aliasToSubq 属性）保存子查询的 QB 对象，aliasToSubq key 值是子查询的别名 QB#qbp 即 QBParseInfo 保存一个基本 SQL 单元中的给个操作部分的 AST Tree 结构，QBParseInfo#nameToDest 这个 HashMap 保存查询单元的输出，key 的形式是 inclause-i（由于 Hive 支持 Multi Insert 语句，所以可能有多个输出），value 是对应的 ASTNode 节点，即 TOK_DESTINATION 节点。类 QBParseInfo 其余 HashMap 属性分别保存输出和各个操作的 ASTNode 节点的对应关系。 QBParseInfo#JoinExpr 保存 TOK_JOIN 节点。QB#QBJoinTree 是对 Join 语法树的结构化。 QB#qbm 保存每个输入表的元信息，比如表在 HDFS 上的路径，保存表数据的文件格式等。 QBExpr 这个对象是为了表示 Union 操作。 QueryBlock AST Tree 生成 QueryBlockAST Tree 生成 QueryBlock 的过程是一个递归的过程，先序遍历 AST Tree，遇到不同的 Token 节点，保存到相应的属性中，主要包含以下几个过程 TOK_QUERY =&gt; 创建 QB 对象，循环递归子节点 TOK_FROM =&gt; 将表名语法部分保存到 QB 对象的aliasToTabs等属性中 TOK_INSERT =&gt; 循环递归子节点 TOK_DESTINATION =&gt; 将输出目标的语法部分保存在 QBParseInfo 对象的 nameToDest 属性中 TOK_SELECT =&gt; 分别将查询表达式的语法部分保存在destToSelExpr、destToAggregationExprs、destToDistinctFuncExprs三个属性中 TOK_WHERE =&gt; 将 Where 部分的语法保存在 QBParseInfo 对象的 destToWhereExpr 属性中 最终样例 SQL 生成两个 QB 对象，QB 对象的关系如下，QB1 是外层查询，QB2 是子查询 12345QB1 \ QB2 Phase3 逻辑操作符 OperatorOperatorHive 最终生成的 MapReduce 任务，Map 阶段和 Reduce 阶段均由 OperatorTree 组成。逻辑操作符，就是在 Map 阶段或者 Reduce 阶段完成单一特定的操作。 基本的操作符包括 TableScanOperator，SelectOperator，FilterOperator，JoinOperator，GroupByOperator，ReduceSinkOperator 从名字就能猜出各个操作符完成的功能，TableScanOperator 从 MapReduce 框架的 Map 接口原始输入表的数据，控制扫描表的数据行数，标记是从原表中取数据。JoinOperator 完成 Join 操作。FilterOperator 完成过滤操作 ReduceSinkOperator 将 Map 端的字段组合序列化为 Reduce Key/value, Partition Key，只可能出现在 Map 阶段，同时也标志着 Hive 生成的 MapReduce 程序中 Map 阶段的结束。 Operator 在 Map Reduce 阶段之间的数据传递都是一个流式的过程。每一个 Operator 对一行数据完成操作后之后将数据传递给 childOperator 计算。 Operator 类的主要属性和方法如下 RowSchema 表示 Operator 的输出字段 InputObjInspector outputObjInspector 解析输入和输出字段 processOp 接收父 Operator 传递的数据，forward 将处理好的数据传递给子 Operator 处理 Hive 每一行数据经过一个 Operator 处理之后，会对字段重新编号，colExprMap 记录每个表达式经过当前 Operator 处理前后的名称对应关系，在下一个阶段逻辑优化阶段用来回溯字段名 由于 Hive 的 MapReduce 程序是一个动态的程序，即不确定一个 MapReduce Job 会进行什么运算，可能是 Join，也可能是 GroupBy，所以 Operator 将所有运行时需要的参数保存在 OperatorDesc 中，OperatorDesc 在提交任务前序列化到 HDFS 上，在 MapReduce 任务执行前从 HDFS 读取并反序列化。Map 阶段 OperatorTree 在 HDFS 上的位置在 Job.getConf(“hive.exec.plan”) + “/map.xml” QueryBlock QueryBlock 生成 Operator TreeQueryBlock 生成 Operator Tree 就是遍历上一个过程中生成的 QB 和 QBParseInfo 对象的保存语法的属性，包含如下几个步骤： QB#aliasToSubq =&gt; 有子查询，递归调用 QB#aliasToTabs =&gt; TableScanOperator QBParseInfo#joinExpr =&gt; QBJoinTree =&gt; ReduceSinkOperator + JoinOperator QBParseInfo#destToWhereExpr =&gt; FilterOperator QBParseInfo#destToGroupby =&gt; ReduceSinkOperator + GroupByOperator QBParseInfo#destToOrderby =&gt; ReduceSinkOperator + ExtractOperator 由于 Join/GroupBy/OrderBy 均需要在 Reduce 阶段完成，所以在生成相应操作的 Operator 之前都会先生成一个 ReduceSinkOperator，将字段组合并序列化为 Reduce Key/value, Partition Key 接下来详细分析样例 SQL 生成 OperatorTree 的过程 先序遍历上一个阶段生成的 QB 对象 首先根据子 QueryBlock QB2#aliasToTabs {du=dim.user, c=detail.usersequence_client, p=fact.orderpayment}生成 TableScanOperator 12TableScanOperator(“dim.user”) TS[0]TableScanOperator(“detail.usersequence_client”) TS[1] TableScanOperator(“fact.orderpayment”) TS[2] 先序遍历QBParseInfo#joinExpr生成QBJoinTree，类QBJoinTree也是一个树状结构，QBJoinTree保存左右表的 ASTNode 和这个查询的别名，最终生成的查询树如下 12345 base / \ p du / \c p 前序遍历QBJoinTree，先生成detail.usersequence_client和fact.orderpayment的 Join 操作树 Join to Operator 图中 TS=TableScanOperator RS=ReduceSinkOperator JOIN=JoinOperator 生成中间表与 dim.user 的 Join 操作树 Join to Operator 根据 QB2 QBParseInfo#destToWhereExpr 生成FilterOperator。此时 QB2 遍历完成。 下图中 SelectOperator 在某些场景下会根据一些条件判断是否需要解析字段。 Where to Operator 图中 FIL= FilterOperator SEL= SelectOperator 根据 QB1 的 QBParseInfo#destToGroupby 生成 ReduceSinkOperator + GroupByOperator GroupBy to Operator 图中 GBY= GroupByOperator GBY[12] 是 HASH 聚合，即在内存中通过 Hash 进行聚合运算 最终都解析完后，会生成一个 FileSinkOperator，将数据写入 HDFS FileSinkOperator 图中 FS=FileSinkOperator Phase4 逻辑层优化器大部分逻辑层优化器通过变换 OperatorTree，合并操作符，达到减少 MapReduce Job，减少 shuffle 数据量的目的。 名称 作用 ② SimpleFetchOptimizer 优化没有GroupBy表达式的聚合查询 ② MapJoinProcessor MapJoin，需要SQL中提供hint，0.11版本已不用 ② BucketMapJoinOptimizer BucketMapJoin ② GroupByOptimizer Map端聚合 ① ReduceSinkDeDuplication 合并线性的OperatorTree中partition/sort key相同的reduce ① PredicatePushDown 谓词前置 ① CorrelationOptimizer 利用查询中的相关性，合并有相关性的Job，HIVE-2206 ColumnPruner 字段剪枝 表格中①的优化器均是一个 Job 干尽可能多的事情 / 合并。②的都是减少 shuffle 数据量，甚至不做 Reduce。 CorrelationOptimizer 优化器非常复杂，都能利用查询中的相关性，合并有相关性的 Job，参考 Hive Correlation Optimizer 对于样例 SQL，有两个优化器对其进行优化。下面分别介绍这两个优化器的作用，并补充一个优化器 ReduceSinkDeDuplication 的作用 PredicatePushDown 优化器断言判断提前优化器将 OperatorTree 中的 FilterOperator 提前到 TableScanOperator 之后 PredicatePushDown NonBlockingOpDeDupProc 优化器NonBlockingOpDeDupProc优化器合并 SEL-SEL 或者 FIL-FIL 为一个 Operator NonBlockingOpDeDupProc ReduceSinkDeDuplication 优化器ReduceSinkDeDuplication 可以合并线性相连的两个 RS。实际上 CorrelationOptimizer 是 ReduceSinkDeDuplication 的超集，能合并线性和非线性的操作 RS，但是 Hive 先实现的 ReduceSinkDeDuplication 譬如下面这条 SQL 语句 1from (select key, value from src group by key, value) s select s.key group by s.key; 经过前面几个阶段之后，会生成如下的 OperatorTree，两个 Tree 是相连的，这里没有画到一起 ReduceSinkDeDuplication 这时候遍历 OperatorTree 后能发现前前后两个 RS 输出的 Key 值和 PartitionKey 如下 Key PartitionKey childRS key key parentRS key,value key,value ReduceSinkDeDuplication 优化器检测到：1. pRS Key 完全包含 cRS Key，且排序顺序一致；2. pRS PartitionKey 完全包含 cRS PartitionKey。符合优化条件，会对执行计划进行优化。 ReduceSinkDeDuplication 将 childRS 和 parentheRS 与 childRS 之间的 Operator 删掉，保留的 RS 的 Key 为 key,value 字段，PartitionKey 为 key 字段。合并后的 OperatorTree 如下： ReduceSinkDeDuplication Phase5 OperatorTree 生成 MapReduce Job 的过程OperatorTree 转化为 MapReduce Job 的过程分为下面几个阶段 对输出表生成 MoveTask 从 OperatorTree 的其中一个根节点向下深度优先遍历 ReduceSinkOperator 标示 Map/Reduce 的界限，多个 Job 间的界限 遍历其他根节点，遇过碰到 JoinOperator 合并 MapReduceTask 生成 StatTask 更新元数据 剪断 Map 与 Reduce 间的 Operator 的关系 对输出表生成 MoveTask由上一步 OperatorTree 只生成了一个 FileSinkOperator，直接生成一个 MoveTask，完成将最终生成的 HDFS 临时文件移动到目标表目录下 12MoveTask[Stage-0]Move Operator 开始遍历将 OperatorTree 中的所有根节点保存在一个 toWalk 的数组中，循环取出数组中的元素（省略 QB1，未画出） 开始遍历 取出最后一个元素 TS[p] 放入栈 opStack{TS[p]} 中 Rule #1 TS% 生成 MapReduceTask 对象，确定 MapWork发现栈中的元素符合下面规则 R1（这里用 python 代码简单表示） 1&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == &quot;TS%&quot; 生成一个MapReduceTask[Stage-1]对象，MapReduceTask[Stage-1]对象的MapWork属性保存 Operator 根节点的引用。由于 OperatorTree 之间之间的 Parent Child 关系，这个时候MapReduceTask[Stage-1]包含了以TS[p]为根的所有 Operator Stage-1 生成 Map 阶段 Rule #2 TS%.*RS% 确定 ReduceWork继续遍历 TS[p] 的子 Operator，将子 Operator 存入栈 opStack 中 当第一个 RS 进栈后，即栈 opStack = {TS[p], FIL[18], RS[4]} 时，就会满足下面的规则 R2 1&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == &quot;TS%.*RS%&quot; 这时候在MapReduceTask[Stage-1]对象的ReduceWork属性保存JOIN[5]的引用 Stage-1 生成 Reduce 阶段 Rule #3 RS%.*RS% 生成新 MapReduceTask 对象，切分 MapReduceTask继续遍历 JOIN[5] 的子 Operator，将子 Operator 存入栈 opStack 中 当第二个 RS 放入栈时，即当栈opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6]}时，就会满足下面的规则 R3 1&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == “RS%.*RS%” //循环遍历opStack的每一个后缀数组 这时候创建一个新的MapReduceTask[Stage-2]对象，将 OperatorTree 从JOIN[5]和RS[6]之间剪开，并为JOIN[5]生成一个子 Operator FS[19]，RS[6]生成一个TS[20]，MapReduceTask[Stage-2]对象的MapWork属性保存TS[20]的引用。 新生成的FS[19]将中间数据落地，存储在 HDFS 临时文件中。 Stage-2 继续遍历 RS[6] 的子 Operator，将子 Operator 存入栈 opStack 中 当opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6], JOIN[8], SEL[10], GBY[12], RS[13]}时，又会满足 R3 规则 同理生成MapReduceTask[Stage-3]对象，并切开 Stage-2 和 Stage-3 的 OperatorTree Stage-3 R4 FS% 连接 MapReduceTask 与 MoveTask最终将所有子 Operator 存入栈中之后，opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6], JOIN[8], SEL[10], GBY[12], RS[13], GBY[14], SEL[15], FS[17]} 满足规则 R4 1&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == “FS%” 这时候将MoveTask与MapReduceTask[Stage-3]连接起来，并生成一个StatsTask，修改表的元信息 MoveTask 合并 Stage此时并没有结束，还有两个根节点没有遍历。 将 opStack 栈清空，将 toWalk 的第二个元素加入栈。会发现opStack = {TS[du]}继续满足 R1 TS%，生成MapReduceTask[Stage-5] Stage-5 继续从TS[du]向下遍历，当opStack={TS[du], RS[7]}时，满足规则 R2 TS%.*RS% 此时将JOIN[8]保存为MapReduceTask[Stage-5]的ReduceWork时，发现在一个 Map 对象保存的 Operator 与 MapReduceWork 对象关系的Map&lt;Operator, MapReduceWork&gt;对象中发现，JOIN[8]已经存在。此时将MapReduceTask[Stage-2]和MapReduceTask[Stage-5]合并为一个 MapReduceTask 合并 Stage-2 和 Stage-5 同理从最后一个根节点TS[c]开始遍历，也会对 MapReduceTask 进行合并 合并 Stage-1 和 Stage-6 切分 Map Reduce 阶段最后一个阶段，将 MapWork 和 ReduceWork 中的 OperatorTree 以 RS 为界限剪开 切分 Map Reduce 阶段 OperatorTree 生成 MapReduceTask 全貌最终共生成 3 个 MapReduceTask，如下图 OperatorTree 生成 MapReduceTask 全貌 Phase6 物理层优化器这里不详细介绍每个优化器的原理，单独介绍一下 MapJoin 的优化器 名称 作用 Vectorizer HIVE-4160，将在0.13中发布 SortMergeJoinResolver 与bucket配合，类似于归并排序 SamplingOptimizer 并行order by优化器，在0.12中发布 CommonJoinResolver + MapJoinResolver MapJoin优化器 MapJoin 原理 mapjoin 原理 MapJoin 简单说就是在 Map 阶段将小表读入内存，顺序扫描大表完成 Join。 上图是 Hive MapJoin 的原理图，出自 Facebook 工程师 Liyin Tang 的一篇介绍 Join 优化的 slice，从图中可以看出 MapJoin 分为两个阶段： 通过 MapReduce Local Task，将小表读入内存，生成 HashTableFiles 上传至 Distributed Cache 中，这里会对 HashTableFiles 进行压缩。 MapReduce Job 在 Map 阶段，每个 Mapper 从 Distributed Cache 读取 HashTableFiles 到内存中，顺序扫描大表，在 Map 阶段直接进行 Join，将数据传递给下一个 MapReduce 任务。 conditionaltask 如果 Join 的两张表一张表是临时表，就会生成一个 ConditionalTask，在运行期间判断是否使用 MapJoin CommonJoinResolver 优化器CommonJoinResolver 优化器就是将 CommonJoin 转化为 MapJoin，转化过程如下 深度优先遍历 Task Tree 找到 JoinOperator，判断左右表数据量大小 对与小表 + 大表 =&gt; MapJoinTask，对于小 / 大表 + 中间表 =&gt; ConditionalTask 遍历上一个阶段生成的 MapReduce 任务，发现MapReduceTask[Stage-2] JOIN[8]中有一张表为临时表，先对 Stage-2 进行深度拷贝（由于需要保留原始执行计划为 Backup Plan，所以这里将执行计划拷贝了一份），生成一个 MapJoinOperator 替代 JoinOperator，然后生成一个 MapReduceLocalWork 读取小表生成 HashTableFiles 上传至 DistributedCache 中。 mapjoin 变换 MapReduceTask 经过变换后的执行计划如下图所示 mapjoin 变换 MapJoinResolver 优化器MapJoinResolver 优化器遍历 Task Tree，将所有有 local work 的 MapReduceTask 拆成两个 Task MapJoinResolver 最终 MapJoinResolver 处理完之后，执行计划如下图所示 MapJoinResolver Hive SQL 编译过程的设计从上述整个 SQL 编译的过程，可以看出编译过程的设计有几个优点值得学习和借鉴 使用 Antlr 开源软件定义语法规则，大大简化了词法和语法的编译解析过程，仅仅需要维护一份语法文件即可。 整体思路很清晰，分阶段的设计使整个编译过程代码容易维护，使得后续各种优化器方便的以可插拔的方式开关，譬如 Hive 0.13 最新的特性 Vectorization 和对 Tez 引擎的支持都是可插拔的。 每个 Operator 只完成单一的功能，简化了整个 MapReduce 程序。 社区发展方向Hive 依然在迅速的发展中，为了提升 Hive 的性能，hortonworks 公司主导的 Stinger 计划提出了一系列对 Hive 的改进，比较重要的改进有： Vectorization - 使 Hive 从单行单行处理数据改为批量处理方式，大大提升了指令流水线和缓存的利用率 Hive on Tez - 将 Hive 底层的 MapReduce 计算框架替换为 Tez 计算框架。Tez 不仅可以支持多 Reduce 阶段的任务 MRR，还可以一次性提交执行计划，因而能更好的分配资源。 Cost Based Optimizer - 使 Hive 能够自动选择最优的 Join 顺序，提高查询速度 Implement insert, update, and delete in Hive with full ACID support - 支持表按主键的增量更新 我们也将跟进社区的发展，结合自身的业务需要，提升 Hive 型 ETL 流程的性能 参考Antlr: http://www.antlr.org/ Wiki Antlr 介绍: http://en.wikipedia.org/wiki/ANTLR Hive Wiki: https://cwiki.apache.org/confluence/display/Hive/Home HiveSQL 编译过程: http://www.slideshare.net/recruitcojp/internal-hive Join Optimization in Hive: Join Strategies in Hive from the 2011 Hadoop Summit (Liyin Tang, Namit Jain) Hive Design Docs: https://cwiki.apache.org/confluence/display/Hive/DesignDocs]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive中Join的类型和用法]]></title>
    <url>%2F2019%2F07%2F09%2FHive%2Fjoin%2F</url>
    <content type="text"><![CDATA[一图以示之： 类型 定义 语法 等效 内连接 只连接匹配的行 inner join join 左外连接 包含左边表的全部行以及右边表中全部匹配的行 left outer join left join 右外连接 包含右边表的全部行以及左边表中全部匹配的行 right outer join right join 全外连接 包含左、右两个表的全部行，不管在另一边表中是否存在与它们匹配的行 full out join full join 左半连接 以left semi join关键字前面的表为主表，返回主表的KEY也在副表中的记录 left semi join 交叉连接 生成笛卡尔积—它不适用任何匹配或者选取条件，而是直接讲一个数据源中的每一行与另个数据源的每一行匹配 cross join join 不加on条件 in/existsexists的执行原理： 对外表做loop循环，每次loop循环再对内表（子查询）进行查询，那么因为对内表的查询使用的索引（内表效率高，故可用大表），而外表有多大都需要遍历，不可避免（尽量用小表），故内表大的使用exists，可加快效率； in的执行原理 是把外表和内表做hash连接，先查询内表，再把内表结果与外表匹配，对外表使用索引（外表效率高，可用大表），而内表多大都需要查询，不可避免，故外表大的使用in，可加快效率。 使用场景说明：12345678910SELECT c.CustomerId, c.CompanyNameFROM Customers cWHERE EXISTS ( SELECT OrderID FROM Orders o WHERE o.CustomerID = c.CustomerID ) 分析：这里使用exists的原因是，订单表里面可能记录很大，而客户表是一个相当较小的表，这样查询的话 是一种优化方式。 1234567891011SELECT * FROM Orders WHERE CustomerId in (id1,id2,id3);SELECT *FROM OrdersWHERE CustomerID in ( SELECT CustomerId FROM Customers WHERE customer_type = 1 ) 分析 ：这里我只查找客户编号是id1,id2,id3 的人的订单信息. in就特别合适了。 注意：in后面子查询可以使用任何子查询（或常数），exists后面的只能是相关子查询（不然没意义） left semi join 与 inner join 相同点与区别hive 的 join 类型有好几种，其实都是把 MR 中的几种方式都封装实现了，其中 join on、left semi join 算是里边具有代表性，且使用频率较高的 join 方式。 1.联系 他们都是 hive join 方式的一种，join on 属于 common join（shuffle join/reduce join），而 left semi join 则属于 map join（broadcast join）的一种变体，从名字可以看出他们的实现原理有差异。 2.区别 （1）Semi Join，也叫半连接，是从分布式数据库中借鉴过来的方法。它的产生动机是：对于reduce side join，跨机器的数据传输量非常大，这成了join操作的一个瓶颈，如果能够在map端过滤掉不会参加join操作的数据，则可以大大节省网络IO，提升执行效率。实现方法很简单：选取一个小表，假设是File1，将其参与join的key抽取出来，保存到文件File3中，File3文件一般很小，可以放到内存中。在map阶段，使用DistributedCache将File3复制到各个TaskTracker上，然后将File2中不在File3中的key对应的记录过滤掉，剩下的reduce阶段的工作与reduce side join相同。由于 hive 中没有 in/exist 这样的子句（新版将支持），所以需要将这种类型的子句转成 left semi join。left semi join 是只传递表的 join key 给 map 阶段 , 如果 key 足够小还是执行 map join, 如果不是则还是 common join。 （2）left semi join 子句中右边的表只能在 ON 子句中设置过滤条件，在 WHERE 子句、SELECT 子句或其他地方过滤都不行。 （3）对待右表中重复key的处理方式差异：因为 left semi join 是 in(keySet) 的关系，遇到右表重复记录，左表会跳过，而 join on 则会一直遍历。 最后的结果是这会造成性能，以及 join 结果上的差异。 （4）left semi join 中最后 select 的结果只许出现左表，因为右表只有 join key 参与关联计算了，而 join on 默认是整个关系模型都参与计算了。 注意：大多数情况下 JOIN ON 和 left semi on 是对等的，但是在上述情况下会出现重复记录，导致结果差异，所以大家在使用的时候最好能了解这两种方式的原理，避免掉“坑”。 示例： 1SELECT a.key, a.val FROM a WHERE a.key in (SELECT b.key FROM b); 可以被改写为： 1SELECT a.key, a.val FROM a LEFT SEMI JOIN b on (a.key = b.key) 特点： 1、left semi join 的限制是， JOIN 子句中右边的表只能在 ON 子句中设置过滤条件，在 WHERE 子句、SELECT 子句或其他地方过滤都不行。 2、left semi join 是只传递表的 join key 给 map 阶段，因此left semi join 中最后 select 的结果只许出现左表。 3、因为 left semi join 是 in(keySet) 的关系，遇到右表重复记录，左表会跳过，而 join 则会一直遍历。这就导致右表有重复值得情况下 left semi join 只产生一条，join 会产生多条，也会导致 left semi join 的性能更高。 比如以下A表和B表进行 join 或 left semi join，然后 select 出所有字段，结果区别如下： 注意：蓝色叉的那一列实际是不存在left semi join中的，因为最后 select 的结果只许出现左表。 参考： Hive 中的 LEFT SEMI JOIN 与 JOIN ON Hive中Join的类型和用法 https://zhuanlan.zhihu.com/p/25435517 hive 的 left semi join 讲解 MapJoin和ReduceJoin区别及优化]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive的三种Join方式]]></title>
    <url>%2F2019%2F07%2F09%2FHive%2Fjoin_task%2F</url>
    <content type="text"><![CDATA[Hive中就是把Map，Reduce的Join拿过来，通过SQL来表示。参考链接：https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Joins Common/Shuffle/Reduce Join假设要进行join的数据分别来自File1和File2 common join是一种最简单的join方式，其主要思想如下： 在map阶段，map函数同时读取两个文件File1和File2，为了区分两种来源的key/value数据对，对每条数据打一个标签 （tag）,比如：tag=0表示来自文件File1，tag=2表示来自文件File2。即：map阶段的主要任务是对不同文件中的数据打标签。 在reduce阶段，reduce函数获取key相同的来自File1和File2文件的value list， 然后对于同一个key，对File1和File2中的数据进行join（笛卡尔乘积）。即：reduce阶段进行实际的连接操作。 Map Join之所以存在reduce side join，是因为在map阶段不能获取所有需要的join字段，即：同一个key对应的字段可能位于不同map中。Reduce side join是非常低效的，因为shuffle阶段要进行大量的数据传输。 Map side join是针对以下场景进行的优化：两个待连接表中，有一个表非常大，而另一个表非常小，以至于小表可以直接存放到内存中。这样，我们可以将小表复制多 份，让每个map task内存中存在一份（比如存放到hash table中），然后只扫描大表：对于大表中的每一条记录key/value，在hash table中查找是否有相同的key的记录，如果有，则连接后输出即可。 为了支持文件的复制，Hadoop提供了一个类DistributedCache，使用该类的方法如下： （1）用户使用静态方法DistributedCache.addCacheFile()指定要复制的文件，它的参数是文件的URI（如果是 HDFS上的文件，可以这样：hdfs://namenode:9000/home/XXX/file，其中9000是自己配置的NameNode端口 号）。JobTracker在作业启动之前会获取这个URI列表，并将相应的文件拷贝到各个TaskTracker的本地磁盘上。（2）用户使用 DistributedCache.getLocalCacheFiles()方法获取文件目录，并使用标准的文件读写API读取相应的文件。 1） 大小表连接： 如果一张表的数据很大，另外一张表很少(&lt;1000行)，那么我们可以将数据量少的那张表放到内存里面，在map端做join。 Hive支持Map Join，用法如下 12select /*+ MAPJOIN(time_dim) */ count(1) fromstore_sales join time_dim on (ss_sold_time_sk = t_time_sk) 2） 需要做不等值join操作（a.x &lt; b.y 或者 a.x like b.y等） 这种操作如果直接使用join的话语法不支持不等于操作，hive语法解析会直接抛出错误 如果把不等于写到where里会造成笛卡尔积，数据异常增大，速度会很慢。甚至会任务无法跑成功~ 根据mapjoin的计算原理，MapJoin会把小表全部读入内存中，在map阶段直接拿另外一个表的数据和内存中表数据做匹配。这种情况下即使笛卡尔积也不会对任务运行速度造成太大的效率影响。 而且hive的where条件本身就是在map阶段进行的操作，所以在where里写入不等值比对的话，也不会造成额外负担。 12345select /*+ MAPJOIN(a) */a.start_level, b.*from dim_level ajoin (select * from test) bwhere b.xx&gt;=a.start_level and b.xx&lt;end_level; 3） MAPJOIN 结合 UNIONALL原始sql： 1234567select a.*,coalesce(c.categoryid,’NA’) as app_categoryfrom (select * from t_aa_pvid_ctr_hour_js_mes1) aleft outer join(select * fromt_qd_cmfu_book_info_mes) con a.app_id=c.book_id; 速度很慢，老办法，先查下数据分布: 1234567select *from(selectapp_id,count(1) cntfromt_aa_pvid_ctr_hour_js_mes1group by app_id) torder by cnt DESClimit 50; 数据分布如下： 123456789101112131415NA 6173701292 1182933141 40673814d 20151236b 1846306s 11242465 6752408 6422316 611104t 5969734 5794733 4895167 4759999 373395107580 10508 我们可以看到除了NA是有问题的异常值，还有appid=1~9的数据也很多，而这些数据是可以关联到的，所以这里不能简单的随机函数了。而fromt_qd_cmfu_book_info_mes这张app库表，又有几百万数据，太大以致不能放入内存使用mapjoin。 解决方：首先将appid=NA和1到9的数据存入一组，并使用mapjoin与维表（维表也限定appid=1~9，这样内存就放得下了）关联，而除此之外的数据存入另一组，使用普通的join，最后使用union all 放到一起。 1234567891011121314151617181920select a.*,coalesce(c.categoryid,’NA’) as app_categoryfrom --if app_id isnot number value or &lt;=9,then not join(select * fromt_aa_pvid_ctr_hour_js_mes1where cast(app_id asint)&gt;9) aleft outer join(select * fromt_qd_cmfu_book_info_meswhere cast(book_id asint)&gt;9) con a.app_id=c.book_idunion allselect /*+ MAPJOIN(c)*/a.*,coalesce(c.categoryid,’NA’) as app_categoryfrom –if app_id&lt;=9,use map join(select * fromt_aa_pvid_ctr_hour_js_mes1where coalesce(cast(app_id as int),-999)&lt;=9) aleft outer join(select * fromt_qd_cmfu_book_info_meswhere cast(book_id asint)&lt;=9) c--if app_id is notnumber value,then not joinon a.app_id=c.book_id 设置： 当然也可以让hive自动识别，把join变成合适的Map Join如下所示 注：当设置为true的时候，hive会自动获取两张表的数据，判定哪个是小表，然后放在内存中 12set hive.auto.convert.join=true;select count(*) from store_sales join time_dim on (ss_sold_time_sk = t_time_sk) SMB(Sort-Merge-Buket) Join 场景： 大表对小表应该使用MapJoin，但是如果是大表对大表，如果进行shuffle，那就要人命了啊，第一个慢不用说，第二个容易出异常，既然是两个表进行join，肯定有相同的字段吧。 tb_a - 5亿（按排序分成五份，每份1亿放在指定的数值范围内,类似于分区表） a_id 100001 ~ 110000 - bucket-01-a -1亿 110001 ~ 120000 120001 ~ 130000 130001 ~ 140000 140001 ~ 150000 tb_b - 5亿（同上，同一个桶只能和对应的桶内数据做join） b_id 100001 ~ 110000 - bucket-01-b -1亿 110001 ~ 120000 120001 ~ 130000 130001 ~ 140000 140001 ~ 150000 注：实际生产环境中，一天的数据可能有50G（举例子可以把数据弄大点，比如说10亿分成1000个bucket）。 原理： 在运行SMB Join的时候会重新创建两张表，当然这是在后台默认做的，不需要用户主动去创建，如下所示： 设置（默认是false）： 123set hive.auto.convert.sortmerge.join=trueset hive.optimize.bucketmapjoin=true;set hive.optimize.bucketmapjoin.sortedmerge=true; 总结： 其实在写程序的时候，我们就可以知道哪些是大表哪些是小表，注意调优。 任务执行计划参见 ： Map join和Common join详解 参考： Hive Join的实现原理 Hive的三种Join方式 Map join和Common join详解 SQL join中级篇–hive中 mapreduce join方法分析]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive中集合数据类型Struct，Map和Array]]></title>
    <url>%2F2019%2F07%2F07%2FHive%2Fcollect%2F</url>
    <content type="text"><![CDATA[Hive中的列支持使用struct，map和array集合数据类型。下表中的数据类型实际上调用的是内置函数。 Hive集合数据类型: 数据类型 描述 字面语法示例 STRUCT 数据类型描述字面语法示例和C语言中的struct或者“对象”类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是 STRUCT { first STRING , last STRING} ，那么第 1 个元素可以通过字段名.first来引用 struct(‘John’,’Doe’) MAP MAP 是一组键一值对元组集合，使用数组表示法(例如[‘key’]) 可以访问元素。例如，如果某个列的数据类型是 MAP ，其中键 值对是’first’ -&gt; ‘John’ 和’last’ -&gt; ‘Doe’，那么可以通过字段名[‘last’]获取最后 1 个元素 map(‘first’,’JOIN’,’last’,’Doe’) ARRAY 数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为［’John’, ‘Doe’] , 那么第 2 个元素可以通过数组名[1]进行引用 Array(‘John’,’Doe’) 和基本数据类型一样，这些类型的名称同样是保留字。 大多数的关系型数据库并不支持这些集合数据类型，因此使用它们会趋向于破坏标准格式。例如，在传统数据模型中，structs可能需要由多个不同的表拼装而成，表间需要适当地使用外键来进行连接。 破坏标准格式所带来的一个实际问题是会增大数据冗余的风险，进而导致消耗不必要的磁盘空间，还有可能造成数据不一致，因此当数据发生改变时冗余的拷贝数据可能无法进行相应的同步。 然而，在大数据系统中，不遵循标准格式的一个好处就是可以提高更高吞吐量的数据。当处理的数据的数量级是TB或者PB时，以最少的“头部寻址”来从磁盘上扫描数据是非常必要的。按数据进行封装的话可以通过减少寻址次数来提供查询的速度。而如果根据外键关系关联的话则需要进行磁盘间的寻址操作，这样会有非常高的性能消耗。 建表： 12345678910111213create table collect_test ( id INT, name STRING, hobby ARRAY &lt; STRING &gt;, -- array中元素为String类型 friend MAP &lt; STRING,STRING &gt;, -- map中键和值均为String类型 mark struct &lt; math:int,english:int &gt; -- Struct中元素为Int类型 ) row format delimited fields terminated by ',' -- 字段之间用','分隔 collection items terminated by '_' -- 集合中的元素用'_'分隔 map keys terminated by ':' -- map中键值对之间用':'分隔 lines terminated by '\n -- 行之间用'\n'分隔 默认一般不指定 2、向表test_set中插入数据 1）对于数据量较大，常用的一种方法是通过文件批量导入的方法，比如我现在要将如下的文本中的数据插入到表中 1231,xiaoming,basketball_game,xiaohong:yes_xiaohua:no,99_751,xiaohong,watch_study,xiaoming:no_xiaohua:not,95_95 可以采用如下语句来实现 1hive -e "load data local inpath '/path/data.txt' overwrite into table collect_test" 2）对于想插入几条数据时，可以采取insert语句来插入数据，比如我们想插入数据 2,xiaohua,basketball_read,xiaoming:no_xiaohong:no,90_90可以采用如下语句来实现，分别通过array,str_to_map,named_struct来包装插入的三种集合数据 1234567INSERT INTO collect_testSELECT 2, 'xiaohua', array('basketball', 'read'), str_to_map('xiaoming:no,xiaohong:no'), named_struct('math', 90, 'english', 90) 对于集合类型的查询，我们还有一种经常使用的方法，查询语句如下 12345678910select id, name, hobby[0], -- 查询第一个hobby friend['xiaohong'], -- 查询map键为xiaohong的value mark.math -- 查询struct中math的值from test_setwhere name = 'xiaoming' 参考： 1.https://blog.csdn.net/qq_41973536/article/details/81627918 2.https://blog.csdn.net/u014414323/article/details/83616361]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive高级函数：窗口函数、分析函数、增强group]]></title>
    <url>%2F2019%2F07%2F07%2FHive%2Fover%2F</url>
    <content type="text"><![CDATA[窗口函数与分析函数应用场景:（1）用于分区排序（2）动态Group By（3）Top N（4）累计计算（5）层次查询 窗口函数 函数 功能 FIRST_VALUE 取分组内排序后，截止到当前行，第一个值 LAST_VALUE 取分组内排序后，截止到当前行，最后一个值 LEAD(col,n,DEFAULT) 用于统计窗口内往下第n行值。第一个参数为列名，第二个参数为往下第n行（可选，默认为1），第三个参数为默认值（当往下第n行为NULL时候，取默认值，如不指定，则为NULL） LAG(col,n,DEFAULT) 与lead相反，用于统计窗口内往上第n行值。第一个参数为列名，第二个参数为往上第n行（可选，默认为1），第三个参数为默认值（当往上第n行为NULL时候，取默认值，如不指定，则为NULL） OVER从句 1、使用标准的聚合函数COUNT、SUM、MIN、MAX、AVG2、使用PARTITION BY语句，使用一个或者多个原始数据类型的列3、使用PARTITION BY与ORDER BY语句，使用一个或者多个数据类型的分区或者排序列4、使用窗口规范，窗口规范支持以下格式： 1(ROWS | RANGE) BETWEEN (UNBOUNDED | [num]) PRECEDING AND ([num] PRECEDING | CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING) 1(ROWS | RANGE) BETWEEN CURRENT ROW AND (CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING) 1(ROWS | RANGE) BETWEEN [num] FOLLOWING AND (UNBOUNDED | [num]) FOLLOWING 当ORDER BY后面缺少窗口从句条件，窗口规范默认是 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW. 当ORDER BY和窗口从句都缺失, 窗口规范默认是 ROW BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING. OVER从句支持以下函数， 但是并不支持和窗口一起使用它们。Ranking函数: Rank, NTile, DenseRank, CumeDist, PercentRank.Lead 和 Lag 函数. 分析函数 ROW_NUMBER() 从1开始，按照顺序，生成分组内记录的序列,比如，按照pv降序排列，生成分组内每天的pv名次,ROW_NUMBER()的应用场景非常多，再比如，获取分组内排序第一的记录;获取一个session中的第一条refer等。 RANK() 生成数据项在分组中的排名，排名相等会在名次中留下空位 DENSE_RANK() 生成数据项在分组中的排名，排名相等会在名次中不会留下空位 CUME_DIST 小于等于当前值的行数/分组内总行数。比如，统计小于等于当前薪水的人数，所占总人数的比例 PERCENT_RANK 分组内当前行的RANK值-1/分组内总行数-1 NTILE(n) 用于将分组数据按照顺序切分成n片，返回当前切片值，如果切片不均匀，默认增加第一个切片的分布。NTILE不支持ROWS BETWEEN，比如 NTILE(2) OVER(PARTITION BY cookieid ORDER BY createtime ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) Hive2.1.0及以后支持Distinct 在聚合函数（SUM, COUNT and AVG）中，支持distinct，但是在ORDER BY 或者 窗口限制不支持。 1COUNT(DISTINCT a) OVER (PARTITION BY c)1 Hive 2.2.0中在使用ORDER BY和窗口限制时支持distinct 1COUNT(DISTINCT a) OVER (PARTITION BY c ORDER BY d ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)1 Hive2.1.0及以后支持在OVER从句中支持聚合函数 123SELECT rank() OVER (ORDER BY sum(b))FROM TGROUP BY a;123 用例测试数据集： user_id device_id user_type amount sex sales log_time u_001 d_001 new 60 man 9 2019-07-01 u_002 d_001 old 40 women 6 2019-07-03 u_003 d_001 new 80 man 5 2019-07-04 u_004 d_001 new 50 man 4 2019-07-05 u_005 d_001 new 30 man 7 2019-07-07 u_006 d_002 old 70 women 10 2019-07-02 u_007 d_002 old 90 man 2 2019-07-03 u_008 d_002 new 10 women 1 2019-07-04 u_009 d_002 new 20 women 3 2019-07-06 u_010 d_002 new 100 women 8 2019-07-17 1.COUNT、SUM、MIN、MAX、AVGrows12345678910111213141516171819202122select user_id, user_type, sales, --默认为从起点到当前行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc) AS sales_1, --从起点到当前行，结果与sales_1相同（若排序字段有重复值则回出现不同，不稳定排序）。 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS sales_2, --当前行+往前3行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS sales_3, --当前行+往前3行+往后1行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING) AS sales_4, --当前行+往后所有行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS sales_5, --分组内所有行 SUM(sales) OVER(PARTITION BY user_type) AS sales_6 from order_detailorder by user_type, sales, user_id 结果： user_id user_type sales sales_1 sales_2 sales_3 sales_4 sales_5 sales_6 u_008 new 1 1 1 1 4 37 37 u_009 new 3 4 4 4 8 36 37 u_004 new 4 8 8 8 13 33 37 u_003 new 5 13 13 13 20 29 37 u_005 new 7 20 20 19 27 24 37 u_010 new 8 28 28 24 33 17 37 u_001 new 9 37 37 29 29 9 37 u_007 old 2 2 2 2 8 18 18 u_002 old 6 8 8 8 18 16 18 u_006 old 10 18 18 18 18 10 18 注意:结果和ORDER BY相关,默认为升序如果不指定ROWS BETWEEN,默认为从起点到当前行;如果不指定ORDER BY，则将分组内所有值累加; 关键是理解ROWS BETWEEN含义,也叫做WINDOW子句：PRECEDING：往前FOLLOWING：往后CURRENT ROW：当前行UNBOUNDED：无界限（起点或终点）UNBOUNDED PRECEDING：表示从前面的起点UNBOUNDED FOLLOWING：表示到后面的终点其他COUNT、AVG，MIN，MAX，和SUM用法一样。 max()函数无论有没有order by 都是计算整个分区的最大值 更多可参考Oracle 数据库的分析语法 理解：执行逻辑为先partiton 内order by 然后sum/max/min 1234567891011121314151617181920212223242526272829参考：https://dacoolbaby.iteye.com/blog/1960373在Hive里面，可以把这一部分独立抽出来做声明。如：select user_id, user_type, sales, log_time, sum(sales) over w1 as s, min(sales) over w1 as mi, max(sales) over w1 as ma, avg(sales) over w1 as agfrom app.order_detail window w1 as(distribute by user_type sort by sales asc rows between 2 preceding and 2 following) ; 其中的window w1 则是抽出声明的窗口部分。如果在一条Hive SQL涉及到多个窗口函数的引用呢？select user_id, user_type, sales, log_time, sum(sales) over w1 as s1, sum(sales) over w2 as s2from app.order_detail window w1 as(distribute by user_type sort by sales asc rows between 2 preceding and 2 following), w2 as(distribute by user_type sort by sales asc rows between unbounded preceding and current row) ; range12345678910参考：https://stackoverflow.com/questions/30809097/sum-over-a-date-range-per-group-in-hiveselect user_id, user_type, sales, log_time, sum(sales) OVER( PARTITION BY user_type ORDER BY unix_timestamp(log_time, 'yyyy-MM-dd') ASC RANGE BETWEEN 86400 PRECEDING and CURRENT ROW) as countfrom app.order_detail 结果： user_id user_type sales log_time count u_001 new 9 2019-07-01 9 u_008 new 1 2019-07-04 6 u_003 new 5 2019-07-04 6 u_004 new 4 2019-07-05 10 u_009 new 3 2019-07-06 7 u_005 new 7 2019-07-07 10 u_010 new 8 2019-07-17 8 u_006 old 10 2019-07-02 10 u_007 old 2 2019-07-03 18 u_002 old 6 2019-07-03 18 理解：当前时间往上三天的累积数量 86400=3600*24 （一天） 2.first_value与last_value12345678910select user_id, user_type, ROW_NUMBER() OVER(PARTITION BY user_type ORDER BY sales) AS row_num, first_value(user_id) over (partition by user_type order by sales desc) as max_sales_user, first_value(user_id) over (partition by user_type order by sales asc) as min_sales_user, last_value(user_id) over (partition by user_type order by sales desc) as curr_last_min_user, last_value(user_id) over (partition by user_type order by sales asc) as curr_last_max_userfrom order_detail; 结果： user_id user_type row_num max_sales_user min_sales_user curr_last_min_user curr_last_max_user u_001 new 7 u_001 u_008 u_001 u_001 u_010 new 6 u_001 u_008 u_010 u_010 u_005 new 5 u_001 u_008 u_005 u_005 u_003 new 4 u_001 u_008 u_003 u_003 u_004 new 3 u_001 u_008 u_004 u_004 u_009 new 2 u_001 u_008 u_009 u_009 u_008 new 1 u_001 u_008 u_008 u_008 u_006 old 3 u_006 u_007 u_006 u_006 u_002 old 2 u_006 u_007 u_002 u_002 u_007 old 1 u_006 u_007 u_007 u_007 3.lead与lag12345678select user_id,device_id, lead(device_id) over (order by sales) as default_after_one_line, lag(device_id) over (order by sales) as default_before_one_line, lead(device_id,2) over (order by sales) as after_two_line, lag(device_id,2,'abc') over (order by sales) as before_two_linefrom order_detail; 4.RANK、ROW_NUMBER、DENSE_RANK1234567select user_id,user_type,sales, RANK() over (partition by user_type order by sales desc) as rank, ROW_NUMBER() over (partition by user_type order by sales desc) as row_number, DENSE_RANK() over (partition by user_type order by sales desc) as desc_rankfrom order_detail; user_id user_type sales log_time rank desc_rank row_number u_010 new 8 2019-07-17 1 1 1 u_005 new 7 2019-07-07 2 2 2 u_009 new 3 2019-07-06 3 3 3 u_004 new 4 2019-07-05 4 4 4 u_008 new 1 2019-07-04 5 5 5 u_003 new 5 2019-07-04 5 5 6 u_001 new 9 2019-07-01 7 6 7 u_007 old 2 2019-07-03 1 1 1 u_002 old 6 2019-07-03 1 1 2 u_006 old 10 2019-07-02 3 2 3 5.NTILE123456789101112131415select user_type,sales, --分组内将数据分成2片 NTILE(2) OVER(PARTITION BY user_type ORDER BY sales) AS nt2, --分组内将数据分成3片 NTILE(3) OVER(PARTITION BY user_type ORDER BY sales) AS nt3, --分组内将数据分成4片 NTILE(4) OVER(PARTITION BY user_type ORDER BY sales) AS nt4, --将所有数据分成4片 NTILE(4) OVER(ORDER BY sales) AS all_nt4from order_detailorder by user_type, sales user_type sales nt2 nt3 nt4 all_nt4 new 1 1 1 1 1 new 3 1 1 1 1 new 4 1 1 2 2 new 5 1 2 2 2 new 7 2 2 3 3 new 8 2 3 3 3 new 9 2 3 4 4 old 2 1 1 1 1 old 6 1 2 2 2 old 10 2 3 3 4 题：求取sale前20%的用户ID 1234567891011select user_idfrom( select user_id, NTILE(5) OVER(ORDER BY sales desc) AS nt from order_detail)Awhere nt=1; 6.CUME_DIST、PERCENT_RANK12345678select user_id,user_type,sales,--没有partition,所有数据均为1组CUME_DIST() OVER(ORDER BY sales) AS cd1,--按照user_type进行分组CUME_DIST() OVER(PARTITION BY user_type ORDER BY sales) AS cd2 from order_detail; user_id user_type sales cd1 cd2 u_008 new 1 0.1 0.14285714285714285 u_009 new 3 0.3 0.2857142857142857 u_004 new 4 0.4 0.42857142857142855 u_003 new 5 0.5 0.5714285714285714 u_005 new 7 0.7 0.7142857142857143 u_010 new 8 0.8 0.8571428571428571 u_001 new 9 0.9 1.0 u_007 old 2 0.2 0.3333333333333333 u_002 old 6 0.6 0.6666666666666666 u_006 old 10 1.0 1.0 1234567891011select user_type,sales,--分组内总行数 SUM(1) OVER(PARTITION BY user_type) AS s, --RANK值 RANK() OVER(ORDER BY sales) AS r, PERCENT_RANK() OVER(ORDER BY sales) AS pr,--分组内 PERCENT_RANK() OVER(PARTITION BY user_type ORDER BY sales) AS prg from order_detail; user_type sales s r pr prg new 1 7 1 0.0 0.0 new 3 7 3 0.2222222222222222 0.16666666666666666 new 4 7 4 0.3333333333333333 0.3333333333333333 new 5 7 5 0.4444444444444444 0.5 new 7 7 7 0.6666666666666666 0.6666666666666666 new 8 7 8 0.7777777777777778 0.8333333333333334 new 9 7 9 0.8888888888888888 1.0 old 2 3 2 0.1111111111111111 0.0 old 6 3 6 0.5555555555555556 0.5 old 10 3 10 1.0 1.0 增强的聚合 Cube和Grouping 和Rollup这几个分析函数通常用于OLAP中，不能累加，而且需要根据不同维度上钻和下钻的指标统计，比如，分小时、天、月的UV数。 GROUPING SETS在一个GROUP BY查询中，根据不同的维度组合进行聚合，等价于将不同维度的GROUP BY结果集进行UNION ALL,其中的GROUPING__ID，表示结果属于哪一个分组集合。 12345678910111213141516171819202122232425select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesGROUPING SETS(user_type,sales) ORDER BY GROUPING__ID;select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesGROUPING SETS(user_type,sales,(user_type,sales)) ORDER BY GROUPING__ID; CUBE根据GROUP BY的维度的所有组合进行聚合。 123456789101112select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesWITH CUBE ORDER BY GROUPING__ID; user_type log_time pv grouping__id NULL NULL 10 0 NULL 2019-07-01 1 2 NULL 2019-07-02 1 2 NULL 2019-07-03 2 2 NULL 2019-07-04 2 2 NULL 2019-07-05 1 2 NULL 2019-07-06 1 2 NULL 2019-07-07 1 2 NULL 2019-07-17 1 2 new NULL 7 1 new 2019-07-01 1 3 new 2019-07-04 2 3 new 2019-07-05 1 3 new 2019-07-06 1 3 new 2019-07-07 1 3 new 2019-07-17 1 3 old NULL 3 1 old 2019-07-02 1 3 old 2019-07-03 2 3 ROLLUP是CUBE的子集，以最左侧的维度为主，从该维度进行层级聚合。 123456789101112select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesWITH ROLLUP ORDER BY GROUPING__ID; 题： 设备总共使用天数和最早、最晚使用的用户和时间 设备连续使用最长的天数 前三天的销售额，后三天的销售额？ 每5分钟统计前一小时的在线人数 参考： https://blog.csdn.net/scgaliguodong123_/article/details/60881166 https://blog.csdn.net/scgaliguodong123_/article/details/60135385 https://dacoolbaby.iteye.com/blog/1960373 https://stackoverflow.com/questions/30809097/sum-over-a-date-range-per-group-in-hive https://blog.csdn.net/Abysscarry/article/details/81408265 http://lxw1234.com/archives/2015/07/367.htm https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
</search>
