<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hive的三种Join方式]]></title>
    <url>%2F2019%2F07%2F09%2FHive%2Fjoin_task%2F</url>
    <content type="text"><![CDATA[Hive中就是把Map，Reduce的Join拿过来，通过SQL来表示。参考链接：https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Joins Common/Shuffle/Reduce Join假设要进行join的数据分别来自File1和File2 common join是一种最简单的join方式，其主要思想如下： 在map阶段，map函数同时读取两个文件File1和File2，为了区分两种来源的key/value数据对，对每条数据打一个标签 （tag）,比如：tag=0表示来自文件File1，tag=2表示来自文件File2。即：map阶段的主要任务是对不同文件中的数据打标签。 在reduce阶段，reduce函数获取key相同的来自File1和File2文件的value list， 然后对于同一个key，对File1和File2中的数据进行join（笛卡尔乘积）。即：reduce阶段进行实际的连接操作。 Map Join之所以存在reduce side join，是因为在map阶段不能获取所有需要的join字段，即：同一个key对应的字段可能位于不同map中。Reduce side join是非常低效的，因为shuffle阶段要进行大量的数据传输。 Map side join是针对以下场景进行的优化：两个待连接表中，有一个表非常大，而另一个表非常小，以至于小表可以直接存放到内存中。这样，我们可以将小表复制多 份，让每个map task内存中存在一份（比如存放到hash table中），然后只扫描大表：对于大表中的每一条记录key/value，在hash table中查找是否有相同的key的记录，如果有，则连接后输出即可。 为了支持文件的复制，Hadoop提供了一个类DistributedCache，使用该类的方法如下： （1）用户使用静态方法DistributedCache.addCacheFile()指定要复制的文件，它的参数是文件的URI（如果是 HDFS上的文件，可以这样：hdfs://namenode:9000/home/XXX/file，其中9000是自己配置的NameNode端口 号）。JobTracker在作业启动之前会获取这个URI列表，并将相应的文件拷贝到各个TaskTracker的本地磁盘上。（2）用户使用 DistributedCache.getLocalCacheFiles()方法获取文件目录，并使用标准的文件读写API读取相应的文件。 1） 大小表连接： 如果一张表的数据很大，另外一张表很少(&lt;1000行)，那么我们可以将数据量少的那张表放到内存里面，在map端做join。 Hive支持Map Join，用法如下 12select /*+ MAPJOIN(time_dim) */ count(1) fromstore_sales join time_dim on (ss_sold_time_sk = t_time_sk) 2） 需要做不等值join操作（a.x &lt; b.y 或者 a.x like b.y等） 这种操作如果直接使用join的话语法不支持不等于操作，hive语法解析会直接抛出错误 如果把不等于写到where里会造成笛卡尔积，数据异常增大，速度会很慢。甚至会任务无法跑成功~ 根据mapjoin的计算原理，MapJoin会把小表全部读入内存中，在map阶段直接拿另外一个表的数据和内存中表数据做匹配。这种情况下即使笛卡尔积也不会对任务运行速度造成太大的效率影响。 而且hive的where条件本身就是在map阶段进行的操作，所以在where里写入不等值比对的话，也不会造成额外负担。 12345select /*+ MAPJOIN(a) */a.start_level, b.*from dim_level ajoin (select * from test) bwhere b.xx&gt;=a.start_level and b.xx&lt;end_level; 3） MAPJOIN 结合 UNIONALL原始sql： 1234567select a.*,coalesce(c.categoryid,’NA’) as app_categoryfrom (select * from t_aa_pvid_ctr_hour_js_mes1) aleft outer join(select * fromt_qd_cmfu_book_info_mes) con a.app_id=c.book_id; 速度很慢，老办法，先查下数据分布: 1234567select *from(selectapp_id,count(1) cntfromt_aa_pvid_ctr_hour_js_mes1group by app_id) torder by cnt DESClimit 50; 数据分布如下： 123456789101112131415NA 6173701292 1182933141 40673814d 20151236b 1846306s 11242465 6752408 6422316 611104t 5969734 5794733 4895167 4759999 373395107580 10508 我们可以看到除了NA是有问题的异常值，还有appid=1~9的数据也很多，而这些数据是可以关联到的，所以这里不能简单的随机函数了。而fromt_qd_cmfu_book_info_mes这张app库表，又有几百万数据，太大以致不能放入内存使用mapjoin。 解决方：首先将appid=NA和1到9的数据存入一组，并使用mapjoin与维表（维表也限定appid=1~9，这样内存就放得下了）关联，而除此之外的数据存入另一组，使用普通的join，最后使用union all 放到一起。 1234567891011121314151617181920select a.*,coalesce(c.categoryid,’NA’) as app_categoryfrom --if app_id isnot number value or &lt;=9,then not join(select * fromt_aa_pvid_ctr_hour_js_mes1where cast(app_id asint)&gt;9) aleft outer join(select * fromt_qd_cmfu_book_info_meswhere cast(book_id asint)&gt;9) con a.app_id=c.book_idunion allselect /*+ MAPJOIN(c)*/a.*,coalesce(c.categoryid,’NA’) as app_categoryfrom –if app_id&lt;=9,use map join(select * fromt_aa_pvid_ctr_hour_js_mes1where coalesce(cast(app_id as int),-999)&lt;=9) aleft outer join(select * fromt_qd_cmfu_book_info_meswhere cast(book_id asint)&lt;=9) c--if app_id is notnumber value,then not joinon a.app_id=c.book_id 设置： 当然也可以让hive自动识别，把join变成合适的Map Join如下所示 注：当设置为true的时候，hive会自动获取两张表的数据，判定哪个是小表，然后放在内存中 12set hive.auto.convert.join=true;select count(*) from store_sales join time_dim on (ss_sold_time_sk = t_time_sk) SMB(Sort-Merge-Buket) Join 场景： 大表对小表应该使用MapJoin，但是如果是大表对大表，如果进行shuffle，那就要人命了啊，第一个慢不用说，第二个容易出异常，既然是两个表进行join，肯定有相同的字段吧。 tb_a - 5亿（按排序分成五份，每份1亿放在指定的数值范围内,类似于分区表） a_id 100001 ~ 110000 - bucket-01-a -1亿 110001 ~ 120000 120001 ~ 130000 130001 ~ 140000 140001 ~ 150000 tb_b - 5亿（同上，同一个桶只能和对应的桶内数据做join） b_id 100001 ~ 110000 - bucket-01-b -1亿 110001 ~ 120000 120001 ~ 130000 130001 ~ 140000 140001 ~ 150000 注：实际生产环境中，一天的数据可能有50G（举例子可以把数据弄大点，比如说10亿分成1000个bucket）。 原理： 在运行SMB Join的时候会重新创建两张表，当然这是在后台默认做的，不需要用户主动去创建，如下所示： 设置（默认是false）： 123set hive.auto.convert.sortmerge.join=trueset hive.optimize.bucketmapjoin=true;set hive.optimize.bucketmapjoin.sortedmerge=true; 总结： 其实在写程序的时候，我们就可以知道哪些是大表哪些是小表，注意调优。 任务执行计划参见 ： Map join和Common join详解 参考： Hive Join的实现原理 Hive的三种Join方式 Map join和Common join详解 SQL join中级篇–hive中 mapreduce join方法分析]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive中Join的类型和用法]]></title>
    <url>%2F2019%2F07%2F09%2FHive%2Fjoin%2F</url>
    <content type="text"><![CDATA[一图以示之： 类型 定义 语法 等效 内连接 只连接匹配的行 inner join join 左外连接 包含左边表的全部行以及右边表中全部匹配的行 left outer join left join 右外连接 包含右边表的全部行以及左边表中全部匹配的行 right outer join right join 全外连接 包含左、右两个表的全部行，不管在另一边表中是否存在与它们匹配的行 full out join full join 左半连接 以left semi join关键字前面的表为主表，返回主表的KEY也在副表中的记录 left semi join 交叉连接 生成笛卡尔积—它不适用任何匹配或者选取条件，而是直接讲一个数据源中的每一行与另个数据源的每一行匹配 cross join join 不加on条件 in/existsexists的执行原理： 对外表做loop循环，每次loop循环再对内表（子查询）进行查询，那么因为对内表的查询使用的索引（内表效率高，故可用大表），而外表有多大都需要遍历，不可避免（尽量用小表），故内表大的使用exists，可加快效率； in的执行原理 是把外表和内表做hash连接，先查询内表，再把内表结果与外表匹配，对外表使用索引（外表效率高，可用大表），而内表多大都需要查询，不可避免，故外表大的使用in，可加快效率。 使用场景说明：12345678910SELECT c.CustomerId, c.CompanyNameFROM Customers cWHERE EXISTS ( SELECT OrderID FROM Orders o WHERE o.CustomerID = c.CustomerID ) 分析：这里使用exists的原因是，订单表里面可能记录很大，而客户表是一个相当较小的表，这样查询的话 是一种优化方式。 1234567891011SELECT * FROM Orders WHERE CustomerId in (id1,id2,id3);SELECT *FROM OrdersWHERE CustomerID in ( SELECT CustomerId FROM Customers WHERE customer_type = 1 ) 分析 ：这里我只查找客户编号是id1,id2,id3 的人的订单信息. in就特别合适了。 注意：in后面子查询可以使用任何子查询（或常数），exists后面的只能是相关子查询（不然没意义） left semi join 与 inner join 相同点与区别hive 的 join 类型有好几种，其实都是把 MR 中的几种方式都封装实现了，其中 join on、left semi join 算是里边具有代表性，且使用频率较高的 join 方式。 1.联系 他们都是 hive join 方式的一种，join on 属于 common join（shuffle join/reduce join），而 left semi join 则属于 map join（broadcast join）的一种变体，从名字可以看出他们的实现原理有差异。 2.区别 （1）Semi Join，也叫半连接，是从分布式数据库中借鉴过来的方法。它的产生动机是：对于reduce side join，跨机器的数据传输量非常大，这成了join操作的一个瓶颈，如果能够在map端过滤掉不会参加join操作的数据，则可以大大节省网络IO，提升执行效率。实现方法很简单：选取一个小表，假设是File1，将其参与join的key抽取出来，保存到文件File3中，File3文件一般很小，可以放到内存中。在map阶段，使用DistributedCache将File3复制到各个TaskTracker上，然后将File2中不在File3中的key对应的记录过滤掉，剩下的reduce阶段的工作与reduce side join相同。由于 hive 中没有 in/exist 这样的子句（新版将支持），所以需要将这种类型的子句转成 left semi join。left semi join 是只传递表的 join key 给 map 阶段 , 如果 key 足够小还是执行 map join, 如果不是则还是 common join。 （2）left semi join 子句中右边的表只能在 ON 子句中设置过滤条件，在 WHERE 子句、SELECT 子句或其他地方过滤都不行。 （3）对待右表中重复key的处理方式差异：因为 left semi join 是 in(keySet) 的关系，遇到右表重复记录，左表会跳过，而 join on 则会一直遍历。 最后的结果是这会造成性能，以及 join 结果上的差异。 （4）left semi join 中最后 select 的结果只许出现左表，因为右表只有 join key 参与关联计算了，而 join on 默认是整个关系模型都参与计算了。 注意：大多数情况下 JOIN ON 和 left semi on 是对等的，但是在上述情况下会出现重复记录，导致结果差异，所以大家在使用的时候最好能了解这两种方式的原理，避免掉“坑”。 示例： 1SELECT a.key, a.val FROM a WHERE a.key in (SELECT b.key FROM b); 可以被改写为： 1SELECT a.key, a.val FROM a LEFT SEMI JOIN b on (a.key = b.key) 特点： 1、left semi join 的限制是， JOIN 子句中右边的表只能在 ON 子句中设置过滤条件，在 WHERE 子句、SELECT 子句或其他地方过滤都不行。 2、left semi join 是只传递表的 join key 给 map 阶段，因此left semi join 中最后 select 的结果只许出现左表。 3、因为 left semi join 是 in(keySet) 的关系，遇到右表重复记录，左表会跳过，而 join 则会一直遍历。这就导致右表有重复值得情况下 left semi join 只产生一条，join 会产生多条，也会导致 left semi join 的性能更高。 比如以下A表和B表进行 join 或 left semi join，然后 select 出所有字段，结果区别如下： 注意：蓝色叉的那一列实际是不存在left semi join中的，因为最后 select 的结果只许出现左表。 参考： Hive 中的 LEFT SEMI JOIN 与 JOIN ON Hive中Join的类型和用法 https://zhuanlan.zhihu.com/p/25435517 hive 的 left semi join 讲解 MapJoin和ReduceJoin区别及优化]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive中集合数据类型Struct，Map和Array]]></title>
    <url>%2F2019%2F07%2F07%2FHive%2Fcollect%2F</url>
    <content type="text"><![CDATA[Hive中的列支持使用struct，map和array集合数据类型。下表中的数据类型实际上调用的是内置函数。 Hive集合数据类型: 数据类型 描述 字面语法示例 STRUCT 数据类型描述字面语法示例和C语言中的struct或者“对象”类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是 STRUCT { first STRING , last STRING} ，那么第 1 个元素可以通过字段名.first来引用 struct(‘John’,’Doe’) MAP MAP 是一组键一值对元组集合，使用数组表示法(例如[‘key’]) 可以访问元素。例如，如果某个列的数据类型是 MAP ，其中键 值对是’first’ -&gt; ‘John’ 和’last’ -&gt; ‘Doe’，那么可以通过字段名[‘last’]获取最后 1 个元素 map(‘first’,’JOIN’,’last’,’Doe’) ARRAY 数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为［’John’, ‘Doe’] , 那么第 2 个元素可以通过数组名[1]进行引用 Array(‘John’,’Doe’) 和基本数据类型一样，这些类型的名称同样是保留字。 大多数的关系型数据库并不支持这些集合数据类型，因此使用它们会趋向于破坏标准格式。例如，在传统数据模型中，structs可能需要由多个不同的表拼装而成，表间需要适当地使用外键来进行连接。 破坏标准格式所带来的一个实际问题是会增大数据冗余的风险，进而导致消耗不必要的磁盘空间，还有可能造成数据不一致，因此当数据发生改变时冗余的拷贝数据可能无法进行相应的同步。 然而，在大数据系统中，不遵循标准格式的一个好处就是可以提高更高吞吐量的数据。当处理的数据的数量级是TB或者PB时，以最少的“头部寻址”来从磁盘上扫描数据是非常必要的。按数据进行封装的话可以通过减少寻址次数来提供查询的速度。而如果根据外键关系关联的话则需要进行磁盘间的寻址操作，这样会有非常高的性能消耗。 建表： 12345678910111213create table collect_test ( id INT, name STRING, hobby ARRAY &lt; STRING &gt;, -- array中元素为String类型 friend MAP &lt; STRING,STRING &gt;, -- map中键和值均为String类型 mark struct &lt; math:int,english:int &gt; -- Struct中元素为Int类型 ) row format delimited fields terminated by ',' -- 字段之间用','分隔 collection items terminated by '_' -- 集合中的元素用'_'分隔 map keys terminated by ':' -- map中键值对之间用':'分隔 lines terminated by '\n -- 行之间用'\n'分隔 默认一般不指定 2、向表test_set中插入数据 1）对于数据量较大，常用的一种方法是通过文件批量导入的方法，比如我现在要将如下的文本中的数据插入到表中 1231,xiaoming,basketball_game,xiaohong:yes_xiaohua:no,99_751,xiaohong,watch_study,xiaoming:no_xiaohua:not,95_95 可以采用如下语句来实现 1hive -e "load data local inpath '/path/data.txt' overwrite into table collect_test" 2）对于想插入几条数据时，可以采取insert语句来插入数据，比如我们想插入数据 2,xiaohua,basketball_read,xiaoming:no_xiaohong:no,90_90可以采用如下语句来实现，分别通过array,str_to_map,named_struct来包装插入的三种集合数据 1234567INSERT INTO collect_testSELECT 2, 'xiaohua', array('basketball', 'read'), str_to_map('xiaoming:no,xiaohong:no'), named_struct('math', 90, 'english', 90) 对于集合类型的查询，我们还有一种经常使用的方法，查询语句如下 12345678910select id, name, hobby[0], -- 查询第一个hobby friend['xiaohong'], -- 查询map键为xiaohong的value mark.math -- 查询struct中math的值from test_setwhere name = 'xiaoming' 参考： 1.https://blog.csdn.net/qq_41973536/article/details/81627918 2.https://blog.csdn.net/u014414323/article/details/83616361]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive高级函数：窗口函数、分析函数、增强group]]></title>
    <url>%2F2019%2F07%2F07%2FHive%2Fover%2F</url>
    <content type="text"><![CDATA[窗口函数与分析函数应用场景:（1）用于分区排序（2）动态Group By（3）Top N（4）累计计算（5）层次查询 窗口函数 函数 功能 FIRST_VALUE 取分组内排序后，截止到当前行，第一个值 LAST_VALUE 取分组内排序后，截止到当前行，最后一个值 LEAD(col,n,DEFAULT) 用于统计窗口内往下第n行值。第一个参数为列名，第二个参数为往下第n行（可选，默认为1），第三个参数为默认值（当往下第n行为NULL时候，取默认值，如不指定，则为NULL） LAG(col,n,DEFAULT) 与lead相反，用于统计窗口内往上第n行值。第一个参数为列名，第二个参数为往上第n行（可选，默认为1），第三个参数为默认值（当往上第n行为NULL时候，取默认值，如不指定，则为NULL） OVER从句 1、使用标准的聚合函数COUNT、SUM、MIN、MAX、AVG2、使用PARTITION BY语句，使用一个或者多个原始数据类型的列3、使用PARTITION BY与ORDER BY语句，使用一个或者多个数据类型的分区或者排序列4、使用窗口规范，窗口规范支持以下格式： 1(ROWS | RANGE) BETWEEN (UNBOUNDED | [num]) PRECEDING AND ([num] PRECEDING | CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING) 1(ROWS | RANGE) BETWEEN CURRENT ROW AND (CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING) 1(ROWS | RANGE) BETWEEN [num] FOLLOWING AND (UNBOUNDED | [num]) FOLLOWING 当ORDER BY后面缺少窗口从句条件，窗口规范默认是 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW. 当ORDER BY和窗口从句都缺失, 窗口规范默认是 ROW BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING. OVER从句支持以下函数， 但是并不支持和窗口一起使用它们。Ranking函数: Rank, NTile, DenseRank, CumeDist, PercentRank.Lead 和 Lag 函数. 分析函数 ROW_NUMBER() 从1开始，按照顺序，生成分组内记录的序列,比如，按照pv降序排列，生成分组内每天的pv名次,ROW_NUMBER()的应用场景非常多，再比如，获取分组内排序第一的记录;获取一个session中的第一条refer等。 RANK() 生成数据项在分组中的排名，排名相等会在名次中留下空位 DENSE_RANK() 生成数据项在分组中的排名，排名相等会在名次中不会留下空位 CUME_DIST 小于等于当前值的行数/分组内总行数。比如，统计小于等于当前薪水的人数，所占总人数的比例 PERCENT_RANK 分组内当前行的RANK值-1/分组内总行数-1 NTILE(n) 用于将分组数据按照顺序切分成n片，返回当前切片值，如果切片不均匀，默认增加第一个切片的分布。NTILE不支持ROWS BETWEEN，比如 NTILE(2) OVER(PARTITION BY cookieid ORDER BY createtime ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) Hive2.1.0及以后支持Distinct 在聚合函数（SUM, COUNT and AVG）中，支持distinct，但是在ORDER BY 或者 窗口限制不支持。 1COUNT(DISTINCT a) OVER (PARTITION BY c)1 Hive 2.2.0中在使用ORDER BY和窗口限制时支持distinct 1COUNT(DISTINCT a) OVER (PARTITION BY c ORDER BY d ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)1 Hive2.1.0及以后支持在OVER从句中支持聚合函数 123SELECT rank() OVER (ORDER BY sum(b))FROM TGROUP BY a;123 用例测试数据集： user_id device_id user_type amount sex sales log_time u_001 d_001 new 60 man 9 2019-07-01 u_002 d_001 old 40 women 6 2019-07-03 u_003 d_001 new 80 man 5 2019-07-04 u_004 d_001 new 50 man 4 2019-07-05 u_005 d_001 new 30 man 7 2019-07-07 u_006 d_002 old 70 women 10 2019-07-02 u_007 d_002 old 90 man 2 2019-07-03 u_008 d_002 new 10 women 1 2019-07-04 u_009 d_002 new 20 women 3 2019-07-06 u_010 d_002 new 100 women 8 2019-07-17 COUNT、SUM、MIN、MAX、AVGrows12345678910111213141516171819202122select user_id, user_type, sales, --默认为从起点到当前行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc) AS sales_1, --从起点到当前行，结果与sales_1相同（若排序字段有重复值则回出现不同，不稳定排序）。 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS sales_2, --当前行+往前3行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS sales_3, --当前行+往前3行+往后1行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING) AS sales_4, --当前行+往后所有行 sum(sales) OVER(PARTITION BY user_type ORDER BY sales asc ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS sales_5, --分组内所有行 SUM(sales) OVER(PARTITION BY user_type) AS sales_6 from order_detailorder by user_type, sales, user_id 结果： user_id user_type sales sales_1 sales_2 sales_3 sales_4 sales_5 sales_6 u_008 new 1 1 1 1 4 37 37 u_009 new 3 4 4 4 8 36 37 u_004 new 4 8 8 8 13 33 37 u_003 new 5 13 13 13 20 29 37 u_005 new 7 20 20 19 27 24 37 u_010 new 8 28 28 24 33 17 37 u_001 new 9 37 37 29 29 9 37 u_007 old 2 2 2 2 8 18 18 u_002 old 6 8 8 8 18 16 18 u_006 old 10 18 18 18 18 10 18 注意:结果和ORDER BY相关,默认为升序如果不指定ROWS BETWEEN,默认为从起点到当前行;如果不指定ORDER BY，则将分组内所有值累加; 关键是理解ROWS BETWEEN含义,也叫做WINDOW子句：PRECEDING：往前FOLLOWING：往后CURRENT ROW：当前行UNBOUNDED：无界限（起点或终点）UNBOUNDED PRECEDING：表示从前面的起点UNBOUNDED FOLLOWING：表示到后面的终点其他COUNT、AVG，MIN，MAX，和SUM用法一样。 max()函数无论有没有order by 都是计算整个分区的最大值 更多可参考Oracle 数据库的分析语法 理解：执行逻辑为先partiton 内order by 然后sum/max/min 1234567891011121314151617181920212223242526272829参考：https://dacoolbaby.iteye.com/blog/1960373在Hive里面，可以把这一部分独立抽出来做声明。如：select user_id, user_type, sales, log_time, sum(sales) over w1 as s, min(sales) over w1 as mi, max(sales) over w1 as ma, avg(sales) over w1 as agfrom app.order_detail window w1 as(distribute by user_type sort by sales asc rows between 2 preceding and 2 following) ; 其中的window w1 则是抽出声明的窗口部分。如果在一条Hive SQL涉及到多个窗口函数的引用呢？select user_id, user_type, sales, log_time, sum(sales) over w1 as s1, sum(sales) over w2 as s2from app.order_detail window w1 as(distribute by user_type sort by sales asc rows between 2 preceding and 2 following), w2 as(distribute by user_type sort by sales asc rows between unbounded preceding and current row) ; range12345678910参考：https://stackoverflow.com/questions/30809097/sum-over-a-date-range-per-group-in-hiveselect user_id, user_type, sales, log_time, sum(sales) OVER( PARTITION BY user_type ORDER BY unix_timestamp(log_time, 'yyyy-MM-dd') ASC RANGE BETWEEN 86400 PRECEDING and CURRENT ROW) as countfrom app.order_detail 结果： user_id user_type sales log_time count u_001 new 9 2019-07-01 9 u_008 new 1 2019-07-04 6 u_003 new 5 2019-07-04 6 u_004 new 4 2019-07-05 10 u_009 new 3 2019-07-06 7 u_005 new 7 2019-07-07 10 u_010 new 8 2019-07-17 8 u_006 old 10 2019-07-02 10 u_007 old 2 2019-07-03 18 u_002 old 6 2019-07-03 18 理解：当前时间往上三天的累积数量 86400=3600*24 （一天） first_value与last_value12345678910select user_id, user_type, ROW_NUMBER() OVER(PARTITION BY user_type ORDER BY sales) AS row_num, first_value(user_id) over (partition by user_type order by sales desc) as max_sales_user, first_value(user_id) over (partition by user_type order by sales asc) as min_sales_user, last_value(user_id) over (partition by user_type order by sales desc) as curr_last_min_user, last_value(user_id) over (partition by user_type order by sales asc) as curr_last_max_userfrom order_detail; 结果： user_id user_type row_num max_sales_user min_sales_user curr_last_min_user curr_last_max_user u_001 new 7 u_001 u_008 u_001 u_001 u_010 new 6 u_001 u_008 u_010 u_010 u_005 new 5 u_001 u_008 u_005 u_005 u_003 new 4 u_001 u_008 u_003 u_003 u_004 new 3 u_001 u_008 u_004 u_004 u_009 new 2 u_001 u_008 u_009 u_009 u_008 new 1 u_001 u_008 u_008 u_008 u_006 old 3 u_006 u_007 u_006 u_006 u_002 old 2 u_006 u_007 u_002 u_002 u_007 old 1 u_006 u_007 u_007 u_007 lead与lag12345678select user_id,device_id, lead(device_id) over (order by sales) as default_after_one_line, lag(device_id) over (order by sales) as default_before_one_line, lead(device_id,2) over (order by sales) as after_two_line, lag(device_id,2,'abc') over (order by sales) as before_two_linefrom order_detail; RANK、ROW_NUMBER、DENSE_RANK1234567select user_id,user_type,sales, RANK() over (partition by user_type order by sales desc) as rank, ROW_NUMBER() over (partition by user_type order by sales desc) as row_number, DENSE_RANK() over (partition by user_type order by sales desc) as desc_rankfrom order_detail; user_id user_type sales log_time rank desc_rank row_number u_010 new 8 2019-07-17 1 1 1 u_005 new 7 2019-07-07 2 2 2 u_009 new 3 2019-07-06 3 3 3 u_004 new 4 2019-07-05 4 4 4 u_008 new 1 2019-07-04 5 5 5 u_003 new 5 2019-07-04 5 5 6 u_001 new 9 2019-07-01 7 6 7 u_007 old 2 2019-07-03 1 1 1 u_002 old 6 2019-07-03 1 1 2 u_006 old 10 2019-07-02 3 2 3 NTILE123456789101112131415select user_type,sales, --分组内将数据分成2片 NTILE(2) OVER(PARTITION BY user_type ORDER BY sales) AS nt2, --分组内将数据分成3片 NTILE(3) OVER(PARTITION BY user_type ORDER BY sales) AS nt3, --分组内将数据分成4片 NTILE(4) OVER(PARTITION BY user_type ORDER BY sales) AS nt4, --将所有数据分成4片 NTILE(4) OVER(ORDER BY sales) AS all_nt4from order_detailorder by user_type, sales user_type sales nt2 nt3 nt4 all_nt4 new 1 1 1 1 1 new 3 1 1 1 1 new 4 1 1 2 2 new 5 1 2 2 2 new 7 2 2 3 3 new 8 2 3 3 3 new 9 2 3 4 4 old 2 1 1 1 1 old 6 1 2 2 2 old 10 2 3 3 4 求取sale前20%的用户ID1234567891011select user_idfrom( select user_id, NTILE(5) OVER(ORDER BY sales desc) AS nt from order_detail)Awhere nt=1; CUME_DIST、PERCENT_RANK12345678select user_id,user_type,sales,--没有partition,所有数据均为1组CUME_DIST() OVER(ORDER BY sales) AS cd1,--按照user_type进行分组CUME_DIST() OVER(PARTITION BY user_type ORDER BY sales) AS cd2 from order_detail; user_id user_type sales cd1 cd2 u_008 new 1 0.1 0.14285714285714285 u_009 new 3 0.3 0.2857142857142857 u_004 new 4 0.4 0.42857142857142855 u_003 new 5 0.5 0.5714285714285714 u_005 new 7 0.7 0.7142857142857143 u_010 new 8 0.8 0.8571428571428571 u_001 new 9 0.9 1.0 u_007 old 2 0.2 0.3333333333333333 u_002 old 6 0.6 0.6666666666666666 u_006 old 10 1.0 1.0 1234567891011select user_type,sales,--分组内总行数 SUM(1) OVER(PARTITION BY user_type) AS s, --RANK值 RANK() OVER(ORDER BY sales) AS r, PERCENT_RANK() OVER(ORDER BY sales) AS pr,--分组内 PERCENT_RANK() OVER(PARTITION BY user_type ORDER BY sales) AS prg from order_detail; user_type sales s r pr prg new 1 7 1 0.0 0.0 new 3 7 3 0.2222222222222222 0.16666666666666666 new 4 7 4 0.3333333333333333 0.3333333333333333 new 5 7 5 0.4444444444444444 0.5 new 7 7 7 0.6666666666666666 0.6666666666666666 new 8 7 8 0.7777777777777778 0.8333333333333334 new 9 7 9 0.8888888888888888 1.0 old 2 3 2 0.1111111111111111 0.0 old 6 3 6 0.5555555555555556 0.5 old 10 3 10 1.0 1.0 增强的聚合 Cube和Grouping 和Rollup这几个分析函数通常用于OLAP中，不能累加，而且需要根据不同维度上钻和下钻的指标统计，比如，分小时、天、月的UV数。 GROUPING SETS在一个GROUP BY查询中，根据不同的维度组合进行聚合，等价于将不同维度的GROUP BY结果集进行UNION ALL,其中的GROUPING__ID，表示结果属于哪一个分组集合。 12345678910111213141516171819202122232425select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesGROUPING SETS(user_type,sales) ORDER BY GROUPING__ID;select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesGROUPING SETS(user_type,sales,(user_type,sales)) ORDER BY GROUPING__ID; CUBE根据GROUP BY的维度的所有组合进行聚合。 123456789101112select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesWITH CUBE ORDER BY GROUPING__ID; user_type log_time pv grouping__id NULL NULL 10 0 NULL 2019-07-01 1 2 NULL 2019-07-02 1 2 NULL 2019-07-03 2 2 NULL 2019-07-04 2 2 NULL 2019-07-05 1 2 NULL 2019-07-06 1 2 NULL 2019-07-07 1 2 NULL 2019-07-17 1 2 new NULL 7 1 new 2019-07-01 1 3 new 2019-07-04 2 3 new 2019-07-05 1 3 new 2019-07-06 1 3 new 2019-07-07 1 3 new 2019-07-17 1 3 old NULL 3 1 old 2019-07-02 1 3 old 2019-07-03 2 3 ROLLUP是CUBE的子集，以最左侧的维度为主，从该维度进行层级聚合。 123456789101112select user_type, sales, count(user_id) as pv, GROUPING__ID from order_detailgroup by user_type,salesWITH ROLLUP ORDER BY GROUPING__ID; 题： 设备总共使用天数和最早、最晚使用的用户和时间 设备连续使用最长的天数 前三天的销售额，后三天的销售额？ 每5分钟统计前一小时的在线人数 参考： https://blog.csdn.net/scgaliguodong123_/article/details/60881166 https://blog.csdn.net/scgaliguodong123_/article/details/60135385 https://dacoolbaby.iteye.com/blog/1960373 https://stackoverflow.com/questions/30809097/sum-over-a-date-range-per-group-in-hive https://blog.csdn.net/Abysscarry/article/details/81408265 http://lxw1234.com/archives/2015/07/367.htm https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
</search>
