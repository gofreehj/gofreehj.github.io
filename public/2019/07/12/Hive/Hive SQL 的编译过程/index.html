<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="原文地址 https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html  Hive 是基于 Hadoop 的一个数据仓库系统，在各大公司都有广泛的应用。美团数据仓库也是基于 Hive 搭建，每天执行近万次的 Hive ETL 计算流程，负责每天数百 GB 的数据存储和分析。Hive 的稳定性和性能对我们的数据分析非常关键。 在几次升">
<meta name="keywords" content="sql">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive SQL 的编译过程">
<meta property="og:url" content="http://yoursite.com/2019/07/12/Hive/Hive SQL 的编译过程/index.html">
<meta property="og:site_name" content="WHJason">
<meta property="og:description" content="原文地址 https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html  Hive 是基于 Hadoop 的一个数据仓库系统，在各大公司都有广泛的应用。美团数据仓库也是基于 Hive 搭建，每天执行近万次的 Hive ETL 计算流程，负责每天数百 GB 的数据存储和分析。Hive 的稳定性和性能对我们的数据分析非常关键。 在几次升">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/73cd82b9.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/bcb10088.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/d7816cf9.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/16d67006.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/68fce9bb.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/53c6802d.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/f7ebe4b8.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/fc74a4ea.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/bb36a793.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/a720d129.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/d368c7d0.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/383ce9ae.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/fa192406.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/5cb009cc.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/8c45914c.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/943f0313.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/67f4d79f.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/9ef61667.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/7088b447.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/38fce288.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/f8a8803e.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/cc1c7642.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/6e876f9e.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/6d3b67c9.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/6799e54e.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/164ea8fd.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/9259eee5.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/129684ea.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/13308564.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/a4cd80c9.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/678dfd68.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/4e209569.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/136eb26d.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/1278f2fa.png">
<meta property="og:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/2a6ea0e2.png">
<meta property="og:updated_time" content="2019-07-12T11:46:42.031Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hive SQL 的编译过程">
<meta name="twitter:description" content="原文地址 https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html  Hive 是基于 Hadoop 的一个数据仓库系统，在各大公司都有广泛的应用。美团数据仓库也是基于 Hive 搭建，每天执行近万次的 Hive ETL 计算流程，负责每天数百 GB 的数据存储和分析。Hive 的稳定性和性能对我们的数据分析非常关键。 在几次升">
<meta name="twitter:image" content="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/73cd82b9.png">





  
  
  <link rel="canonical" href="http://yoursite.com/2019/07/12/Hive/Hive SQL 的编译过程/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Hive SQL 的编译过程 | WHJason</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WHJason</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Snow Love</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/12/Hive/Hive SQL 的编译过程/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="WHJason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WHJason">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Hive SQL 的编译过程

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-12 12:33:48 / 修改时间：19:46:42" itemprop="dateCreated datePublished" datetime="2019-07-12T12:33:48+08:00">2019-07-12</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          
            <span id="/2019/07/12/Hive/Hive SQL 的编译过程/" class="post-meta-item leancloud_visitors" data-flag-title="Hive SQL 的编译过程">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          <br>
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span title="本文字数">16k</span>
            </span>
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span title="阅读时长">14 分钟</span>
            </span>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>原文地址 <a href="https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html" target="_blank" rel="noopener">https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html</a></p>
</blockquote>
<p>Hive 是基于 Hadoop 的一个数据仓库系统，在各大公司都有广泛的应用。美团数据仓库也是基于 Hive 搭建，每天执行近万次的 Hive ETL 计算流程，负责每天数百 GB 的数据存储和分析。Hive 的稳定性和性能对我们的数据分析非常关键。</p>
<p>在几次升级 Hive 的过程中，我们遇到了一些大大小小的问题。通过向社区的咨询和自己的努力，在解决这些问题的同时我们对 Hive 将 SQL 编译为 MapReduce 的过程有了比较深入的理解。对这一过程的理解不仅帮助我们解决了一些 Hive 的 bug，也有利于我们优化 Hive SQL，提升我们对 Hive 的掌控力，同时有能力去定制一些需要的功能。</p>
<h2 id="MapReduce-实现基本-SQL-操作的原理"><a href="#MapReduce-实现基本-SQL-操作的原理" class="headerlink" title="MapReduce 实现基本 SQL 操作的原理"></a>MapReduce 实现基本 SQL 操作的原理</h2><p>详细讲解 SQL 编译为 MapReduce 之前，我们先来看看 MapReduce 框架实现 SQL 基本操作的原理</p>
<h3 id="Join-的实现原理"><a href="#Join-的实现原理" class="headerlink" title="Join 的实现原理"></a>Join 的实现原理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select u.name, o.orderid from order o join user u on o.uid = u.uid;</span><br></pre></td></tr></table></figure>

<p>在 map 的输出 value 中为不同表的数据打上 tag 标记，在 reduce 阶段根据 tag 判断数据来源。MapReduce 的过程如下（这里只是说明最基本的 Join 的实现，还有其他的实现方式）</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/73cd82b9.png" alt></p>
<p>MapReduce CommonJoin 的实现</p>
<h3 id="Group-By-的实现原理"><a href="#Group-By-的实现原理" class="headerlink" title="Group By 的实现原理"></a>Group By 的实现原理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select rank, isonline, count(*) from city group by rank, isonline;</span><br></pre></td></tr></table></figure>

<p>将 GroupBy 的字段组合为 map 的输出 key 值，利用 MapReduce 的排序，在 reduce 阶段保存 LastKey 区分不同的 key。MapReduce 的过程如下（当然这里只是说明 Reduce 端的非 Hash 聚合过程）</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/bcb10088.png" alt></p>
<p>MapReduce Group By 的实现</p>
<h3 id="Distinct-的实现原理"><a href="#Distinct-的实现原理" class="headerlink" title="Distinct 的实现原理"></a>Distinct 的实现原理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select dealid, count(distinct uid) num from order group by dealid;</span><br></pre></td></tr></table></figure>

<p>当只有一个 distinct 字段时，如果不考虑 Map 阶段的 Hash GroupBy，只需要将 GroupBy 字段和 Distinct 字段组合为 map 输出 key，利用 mapreduce 的排序，同时将 GroupBy 字段作为 reduce 的 key，在 reduce 阶段保存 LastKey 即可完成去重</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/d7816cf9.png" alt></p>
<p>MapReduce Distinct 的实现</p>
<p>如果有多个 distinct 字段呢，如下面的 SQL</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select dealid, count(distinct uid), count(distinct date) from order group by dealid;</span><br></pre></td></tr></table></figure>

<p>实现方式有两种：</p>
<p>（1）如果仍然按照上面一个 distinct 字段的方法，即下图这种实现方式，无法跟据 uid 和 date 分别排序，也就无法通过 LastKey 去重，仍然需要在 reduce 阶段在内存中通过 Hash 去重</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/16d67006.png" alt></p>
<p>MapReduce Multi Distinct 的实现</p>
<p>（2）第二种实现方式，可以对所有的 distinct 字段编号，每行数据生成 n 行数据，那么相同字段就会分别排序，这时只需要在 reduce 阶段记录 LastKey 即可去重。</p>
<p>这种实现方式很好的利用了 MapReduce 的排序，节省了 reduce 阶段去重的内存消耗，但是缺点是增加了 shuffle 的数据量。</p>
<p>需要注意的是，在生成 reduce value 时，除第一个 distinct 字段所在行需要保留 value 值，其余 distinct 数据行 value 字段均可为空。</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/68fce9bb.png" alt></p>
<p>MapReduce Multi Distinct 的实现</p>
<h2 id="SQL-转化为-MapReduce-的过程"><a href="#SQL-转化为-MapReduce-的过程" class="headerlink" title="SQL 转化为 MapReduce 的过程"></a>SQL 转化为 MapReduce 的过程</h2><p>了解了 MapReduce 实现 SQL 基本操作之后，我们来看看 Hive 是如何将 SQL 转化为 MapReduce 任务的，整个编译过程分为六个阶段：</p>
<ol>
<li>Antlr 定义 SQL 的语法规则，完成 SQL 词法，语法解析，将 SQL 转化为抽象语法树 AST Tree</li>
<li>遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock</li>
<li>遍历 QueryBlock，翻译为执行操作树 OperatorTree</li>
<li>逻辑层优化器进行 OperatorTree 变换，合并不必要的 ReduceSinkOperator，减少 shuffle 数据量</li>
<li>遍历 OperatorTree，翻译为 MapReduce 任务</li>
<li>物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划</li>
</ol>
<p>下面分别对这六个阶段进行介绍</p>
<h3 id="Phase1-SQL-词法，语法解析"><a href="#Phase1-SQL-词法，语法解析" class="headerlink" title="Phase1 SQL 词法，语法解析"></a>Phase1 SQL 词法，语法解析</h3><h4 id="Antlr"><a href="#Antlr" class="headerlink" title="Antlr"></a>Antlr</h4><p>Hive 使用 Antlr 实现 SQL 的词法和语法解析。Antlr 是一种语言识别的工具，可以用来构造领域语言。 这里不详细介绍 Antlr，只需要了解使用 Antlr 构造特定的语言只需要编写一个语法文件，定义词法和语法替换规则即可，Antlr 完成了词法分析、语法分析、语义分析、中间代码生成的过程。</p>
<p>Hive 中语法规则的定义文件在 0.10 版本以前是 Hive.g 一个文件，随着语法规则越来越复杂，由语法规则生成的 Java 解析类可能超过 Java 类文件的最大上限，0.11 版本将 Hive.g 拆成了 5 个文件，词法规则 HiveLexer.g 和语法规则的 4 个文件 SelectClauseParser.g，FromClauseParser.g，IdentifiersParser.g，HiveParser.g。</p>
<h4 id="抽象语法树-AST-Tree"><a href="#抽象语法树-AST-Tree" class="headerlink" title="抽象语法树 AST Tree"></a>抽象语法树 AST Tree</h4><p>经过词法和语法解析后，如果需要对表达式做进一步的处理，使用 Antlr 的抽象语法树语法 Abstract Syntax Tree，在语法分析的同时将输入语句转换成抽象语法树，后续在遍历语法树时完成进一步的处理。</p>
<p>下面的一段语法是 Hive SQL 中 SelectStatement 的语法规则，从中可以看出，SelectStatement 包含 select, from, where, groupby, having, orderby 等子句。 （在下面的语法规则中，箭头表示对于原语句的改写，改写后会加入一些特殊词标示特定语法，比如 TOK_QUERY 标示一个查询块）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">selectStatement</span><br><span class="line">   :</span><br><span class="line">   selectClause</span><br><span class="line">   fromClause</span><br><span class="line">   whereClause?</span><br><span class="line">   groupByClause?</span><br><span class="line">   havingClause?</span><br><span class="line">   orderByClause?</span><br><span class="line">   clusterByClause?</span><br><span class="line">   distributeByClause?</span><br><span class="line">   sortByClause?</span><br><span class="line">   limitClause? -&gt; ^(TOK_QUERY fromClause ^(TOK_INSERT ^(TOK_DESTINATION ^(TOK_DIR TOK_TMP_FILE))</span><br><span class="line">                     selectClause whereClause? groupByClause? havingClause? orderByClause? clusterByClause?</span><br><span class="line">                     distributeByClause? sortByClause? limitClause?))</span><br><span class="line">   ;</span><br></pre></td></tr></table></figure>

<h4 id="样例-SQL"><a href="#样例-SQL" class="headerlink" title="样例 SQL"></a>样例 SQL</h4><p>为了详细说明 SQL 翻译为 MapReduce 的过程，这里以一条简单的 SQL 为例，SQL 中包含一个子查询，最终将数据写入到一张表中</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">FROM</span><br><span class="line">( </span><br><span class="line">  <span class="keyword">SELECT</span></span><br><span class="line">    p.datekey datekey,</span><br><span class="line">    p.userid userid,</span><br><span class="line">    c.clienttype</span><br><span class="line">  <span class="keyword">FROM</span></span><br><span class="line">    detail.usersequence_client c</span><br><span class="line">    <span class="keyword">JOIN</span> fact.orderpayment p <span class="keyword">ON</span> p.orderid = c.orderid</span><br><span class="line">    <span class="keyword">JOIN</span> default.user du <span class="keyword">ON</span> du.userid = p.userid</span><br><span class="line">  <span class="keyword">WHERE</span> p.datekey = <span class="number">20131118</span> </span><br><span class="line">) base</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> <span class="string">`test`</span>.<span class="string">`customer_kpi`</span></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  base.datekey,</span><br><span class="line">  base.clienttype,</span><br><span class="line">  <span class="keyword">count</span>(<span class="keyword">distinct</span> base.userid) buyer_count</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> base.datekey, base.clienttype</span><br></pre></td></tr></table></figure>

<h4 id="SQL-生成-AST-Tree"><a href="#SQL-生成-AST-Tree" class="headerlink" title="SQL 生成 AST Tree"></a>SQL 生成 AST Tree</h4><p>Antlr 对 Hive SQL 解析的代码如下，HiveLexerX，HiveParser 分别是 Antlr 对语法文件 Hive.g 编译后自动生成的词法解析和语法解析类，在这两个类中进行复杂的解析。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">HiveLexerX lexer = new HiveLexerX(new ANTLRNoCaseStringStream(command));    </span><br><span class="line">TokenRewriteStream tokens = new TokenRewriteStream(lexer);</span><br><span class="line">if (ctx != null) &#123;</span><br><span class="line">  ctx.setTokenRewriteStream(tokens);</span><br><span class="line">&#125;</span><br><span class="line">HiveParser parser = new HiveParser(tokens);                                 </span><br><span class="line">parser.setTreeAdaptor(adaptor);</span><br><span class="line">HiveParser.statement_return r = null;</span><br><span class="line">try &#123;</span><br><span class="line">  r = parser.statement();                                                   </span><br><span class="line">&#125; catch (RecognitionException e) &#123;</span><br><span class="line">  e.printStackTrace();</span><br><span class="line">  throw new ParseException(parser.errors);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最终生成的 AST Tree 如下图右侧（使用 Antlr Works 生成，Antlr Works 是 Antlr 提供的编写语法文件的编辑器），图中只是展开了骨架的几个节点，没有完全展开。 子查询 1/2，分别对应右侧第 1/2 两个部分。</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/53c6802d.png" alt></p>
<p>SQL 生成 AST Tree</p>
<p>这里注意一下内层子查询也会生成一个 TOK_DESTINATION 节点。请看上面 SelectStatement 的语法规则，这个节点是在语法改写中特意增加了的一个节点。原因是 Hive 中所有查询的数据均会保存在 HDFS 临时的文件中，无论是中间的子查询还是查询最终的结果，Insert 语句最终会将数据写入表所在的 HDFS 目录下。</p>
<p>详细来看，将内存子查询的 from 子句展开后，得到如下 AST Tree，每个表生成一个 TOK_TABREF 节点，Join 条件生成一个 “=” 节点。其他 SQL 部分类似，不一一详述。</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/f7ebe4b8.png" alt></p>
<p>AST Tree</p>
<h3 id="Phase2-SQL-基本组成单元-QueryBlock"><a href="#Phase2-SQL-基本组成单元-QueryBlock" class="headerlink" title="Phase2 SQL 基本组成单元 QueryBlock"></a>Phase2 SQL 基本组成单元 QueryBlock</h3><p>AST Tree 仍然非常复杂，不够结构化，不方便直接翻译为 MapReduce 程序，AST Tree 转化为 QueryBlock 就是将 SQL 进一部抽象和结构化。</p>
<h4 id="QueryBlock"><a href="#QueryBlock" class="headerlink" title="QueryBlock"></a>QueryBlock</h4><p>QueryBlock 是一条 SQL 最基本的组成单元，包括三个部分：输入源，计算过程，输出。简单来讲一个 QueryBlock 就是一个子查询。</p>
<p>下图为 Hive 中 QueryBlock 相关对象的类图，解释图中几个重要的属性</p>
<ul>
<li>QB#aliasToSubq（表示 QB 类的 aliasToSubq 属性）保存子查询的 QB 对象，aliasToSubq key 值是子查询的别名</li>
<li>QB#qbp 即 QBParseInfo 保存一个基本 SQL 单元中的给个操作部分的 AST Tree 结构，QBParseInfo#nameToDest 这个 HashMap 保存查询单元的输出，key 的形式是 inclause-i（由于 Hive 支持 Multi Insert 语句，所以可能有多个输出），value 是对应的 ASTNode 节点，即 TOK_DESTINATION 节点。类 QBParseInfo 其余 HashMap 属性分别保存输出和各个操作的 ASTNode 节点的对应关系。</li>
<li>QBParseInfo#JoinExpr 保存 TOK_JOIN 节点。QB#QBJoinTree 是对 Join 语法树的结构化。</li>
<li>QB#qbm 保存每个输入表的元信息，比如表在 HDFS 上的路径，保存表数据的文件格式等。</li>
<li>QBExpr 这个对象是为了表示 Union 操作。</li>
</ul>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/fc74a4ea.png" alt></p>
<p>QueryBlock</p>
<h4 id="AST-Tree-生成-QueryBlock"><a href="#AST-Tree-生成-QueryBlock" class="headerlink" title="AST Tree 生成 QueryBlock"></a>AST Tree 生成 QueryBlock</h4><p>AST Tree 生成 QueryBlock 的过程是一个递归的过程，先序遍历 AST Tree，遇到不同的 Token 节点，保存到相应的属性中，主要包含以下几个过程</p>
<ul>
<li>TOK_QUERY =&gt; 创建 QB 对象，循环递归子节点</li>
<li>TOK_FROM =&gt; 将表名语法部分保存到 QB 对象的<code>aliasToTabs</code>等属性中</li>
<li>TOK_INSERT =&gt; 循环递归子节点</li>
<li>TOK_DESTINATION =&gt; 将输出目标的语法部分保存在 QBParseInfo 对象的 nameToDest 属性中</li>
<li>TOK_SELECT =&gt; 分别将查询表达式的语法部分保存在<code>destToSelExpr</code>、<code>destToAggregationExprs</code>、<code>destToDistinctFuncExprs</code>三个属性中</li>
<li>TOK_WHERE =&gt; 将 Where 部分的语法保存在 QBParseInfo 对象的 destToWhereExpr 属性中</li>
</ul>
<p>最终样例 SQL 生成两个 QB 对象，QB 对象的关系如下，QB1 是外层查询，QB2 是子查询</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">QB1</span><br><span class="line"></span><br><span class="line">  \</span><br><span class="line"></span><br><span class="line">   QB2</span><br></pre></td></tr></table></figure>

<h3 id="Phase3-逻辑操作符-Operator"><a href="#Phase3-逻辑操作符-Operator" class="headerlink" title="Phase3 逻辑操作符 Operator"></a>Phase3 逻辑操作符 Operator</h3><h4 id="Operator"><a href="#Operator" class="headerlink" title="Operator"></a>Operator</h4><p>Hive 最终生成的 MapReduce 任务，Map 阶段和 Reduce 阶段均由 OperatorTree 组成。逻辑操作符，就是在 Map 阶段或者 Reduce 阶段完成单一特定的操作。</p>
<p>基本的操作符包括 TableScanOperator，SelectOperator，FilterOperator，JoinOperator，GroupByOperator，ReduceSinkOperator</p>
<p>从名字就能猜出各个操作符完成的功能，TableScanOperator 从 MapReduce 框架的 Map 接口原始输入表的数据，控制扫描表的数据行数，标记是从原表中取数据。JoinOperator 完成 Join 操作。FilterOperator 完成过滤操作</p>
<p>ReduceSinkOperator 将 Map 端的字段组合序列化为 Reduce Key/value, Partition Key，只可能出现在 Map 阶段，同时也标志着 Hive 生成的 MapReduce 程序中 Map 阶段的结束。</p>
<p>Operator 在 Map Reduce 阶段之间的数据传递都是一个流式的过程。每一个 Operator 对一行数据完成操作后之后将数据传递给 childOperator 计算。</p>
<p>Operator 类的主要属性和方法如下</p>
<ul>
<li>RowSchema 表示 Operator 的输出字段</li>
<li>InputObjInspector outputObjInspector 解析输入和输出字段</li>
<li>processOp 接收父 Operator 传递的数据，forward 将处理好的数据传递给子 Operator 处理</li>
<li>Hive 每一行数据经过一个 Operator 处理之后，会对字段重新编号，colExprMap 记录每个表达式经过当前 Operator 处理前后的名称对应关系，在下一个阶段逻辑优化阶段用来回溯字段名</li>
<li>由于 Hive 的 MapReduce 程序是一个动态的程序，即不确定一个 MapReduce Job 会进行什么运算，可能是 Join，也可能是 GroupBy，所以 Operator 将所有运行时需要的参数保存在 OperatorDesc 中，OperatorDesc 在提交任务前序列化到 HDFS 上，在 MapReduce 任务执行前从 HDFS 读取并反序列化。Map 阶段 OperatorTree 在 HDFS 上的位置在 Job.getConf(“hive.exec.plan”) + “/map.xml”</li>
</ul>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/bb36a793.png" alt></p>
<p>QueryBlock</p>
<h4 id="QueryBlock-生成-Operator-Tree"><a href="#QueryBlock-生成-Operator-Tree" class="headerlink" title="QueryBlock 生成 Operator Tree"></a>QueryBlock 生成 Operator Tree</h4><p>QueryBlock 生成 Operator Tree 就是遍历上一个过程中生成的 QB 和 QBParseInfo 对象的保存语法的属性，包含如下几个步骤：</p>
<ul>
<li>QB#aliasToSubq =&gt; 有子查询，递归调用</li>
<li>QB#aliasToTabs =&gt; TableScanOperator</li>
<li>QBParseInfo#joinExpr =&gt; QBJoinTree =&gt; ReduceSinkOperator + JoinOperator</li>
<li>QBParseInfo#destToWhereExpr =&gt; FilterOperator</li>
<li>QBParseInfo#destToGroupby =&gt; ReduceSinkOperator + GroupByOperator</li>
<li>QBParseInfo#destToOrderby =&gt; ReduceSinkOperator + ExtractOperator</li>
</ul>
<p><strong><em>由于 Join/GroupBy/OrderBy 均需要在 Reduce 阶段完成，所以在生成相应操作的 Operator 之前都会先生成一个 ReduceSinkOperator，将字段组合并序列化为 Reduce Key/value, Partition Key</em></strong></p>
<p>接下来详细分析样例 SQL 生成 OperatorTree 的过程</p>
<p>先序遍历上一个阶段生成的 QB 对象</p>
<ol>
<li><p>首先根据子 QueryBlock <code>QB2#aliasToTabs {du=dim.user, c=detail.usersequence_client, p=fact.orderpayment}</code>生成 TableScanOperator</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TableScanOperator(“dim.user”) TS[0]</span><br><span class="line">TableScanOperator(“detail.usersequence_client”) TS[1]       TableScanOperator(“fact.orderpayment”) TS[2]</span><br></pre></td></tr></table></figure>


</li>
</ol>
<ol start="2">
<li><p>先序遍历<code>QBParseInfo#joinExpr</code>生成<code>QBJoinTree</code>，类<code>QBJoinTree</code>也是一个树状结构，<code>QBJoinTree</code>保存左右表的 ASTNode 和这个查询的别名，最终生成的查询树如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">   base</span><br><span class="line">   /  \</span><br><span class="line">  p    du</span><br><span class="line"> /      \</span><br><span class="line">c        p</span><br></pre></td></tr></table></figure>


</li>
</ol>
<ol start="3">
<li>前序遍历<code>QBJoinTree</code>，先生成<code>detail.usersequence_client</code>和<code>fact.orderpayment</code>的 Join 操作树</li>
</ol>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/a720d129.png" alt></p>
<p>Join to Operator</p>
<p><strong><em>图中 TS=TableScanOperator RS=ReduceSinkOperator JOIN=JoinOperator</em></strong></p>
<ol>
<li>生成中间表与 dim.user 的 Join 操作树</li>
</ol>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/d368c7d0.png" alt></p>
<p>Join to Operator</p>
<ol>
<li>根据 QB2 <code>QBParseInfo#destToWhereExpr</code> 生成<code>FilterOperator</code>。此时 QB2 遍历完成。</li>
</ol>
<p>下图中 SelectOperator 在某些场景下会根据一些条件判断是否需要解析字段。</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/383ce9ae.png" alt></p>
<p>Where to Operator</p>
<p><strong><em>图中 FIL= FilterOperator SEL= SelectOperator</em></strong></p>
<ol>
<li>根据 QB1 的 QBParseInfo#destToGroupby 生成 ReduceSinkOperator + GroupByOperator</li>
</ol>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/fa192406.png" alt></p>
<p>GroupBy to Operator</p>
<p><strong><em>图中 GBY= GroupByOperator</em></strong> <strong><em>GBY[12] 是 HASH 聚合，即在内存中通过 Hash 进行聚合运算</em></strong></p>
<ol>
<li>最终都解析完后，会生成一个 FileSinkOperator，将数据写入 HDFS</li>
</ol>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/5cb009cc.png" alt></p>
<p>FileSinkOperator</p>
<p><strong><em>图中 FS=FileSinkOperator</em></strong></p>
<h3 id="Phase4-逻辑层优化器"><a href="#Phase4-逻辑层优化器" class="headerlink" title="Phase4 逻辑层优化器"></a>Phase4 逻辑层优化器</h3><p>大部分逻辑层优化器通过变换 OperatorTree，合并操作符，达到减少 MapReduce Job，减少 shuffle 数据量的目的。</p>
<table>
<thead>
<tr>
<th align="left">名称</th>
<th align="left">作用</th>
</tr>
</thead>
<tbody><tr>
<td align="left">② SimpleFetchOptimizer</td>
<td align="left">优化没有GroupBy表达式的聚合查询</td>
</tr>
<tr>
<td align="left">② MapJoinProcessor</td>
<td align="left">MapJoin，需要SQL中提供hint，0.11版本已不用</td>
</tr>
<tr>
<td align="left">② BucketMapJoinOptimizer</td>
<td align="left">BucketMapJoin</td>
</tr>
<tr>
<td align="left">② GroupByOptimizer</td>
<td align="left">Map端聚合</td>
</tr>
<tr>
<td align="left">① ReduceSinkDeDuplication</td>
<td align="left">合并线性的OperatorTree中partition/sort key相同的reduce</td>
</tr>
<tr>
<td align="left">① PredicatePushDown</td>
<td align="left">谓词前置</td>
</tr>
<tr>
<td align="left">① CorrelationOptimizer</td>
<td align="left">利用查询中的相关性，合并有相关性的Job，HIVE-2206</td>
</tr>
<tr>
<td align="left">ColumnPruner</td>
<td align="left">字段剪枝</td>
</tr>
</tbody></table>
<p>表格中①的优化器均是一个 Job 干尽可能多的事情 / 合并。②的都是减少 shuffle 数据量，甚至不做 Reduce。</p>
<p>CorrelationOptimizer 优化器非常复杂，都能利用查询中的相关性，合并有相关性的 Job，参考 <a href="https://cwiki.apache.org/confluence/display/Hive/Correlation+Optimizer" target="_blank" rel="noopener">Hive Correlation Optimizer</a></p>
<p>对于样例 SQL，有两个优化器对其进行优化。下面分别介绍这两个优化器的作用，并补充一个优化器 ReduceSinkDeDuplication 的作用</p>
<h4 id="PredicatePushDown-优化器"><a href="#PredicatePushDown-优化器" class="headerlink" title="PredicatePushDown 优化器"></a>PredicatePushDown 优化器</h4><p>断言判断提前优化器将 OperatorTree 中的 FilterOperator 提前到 TableScanOperator 之后</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/8c45914c.png" alt></p>
<p>PredicatePushDown</p>
<h4 id="NonBlockingOpDeDupProc-优化器"><a href="#NonBlockingOpDeDupProc-优化器" class="headerlink" title="NonBlockingOpDeDupProc 优化器"></a>NonBlockingOpDeDupProc 优化器</h4><p><code>NonBlockingOpDeDupProc</code>优化器合并 SEL-SEL 或者 FIL-FIL 为一个 Operator</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/943f0313.png" alt></p>
<p>NonBlockingOpDeDupProc</p>
<h4 id="ReduceSinkDeDuplication-优化器"><a href="#ReduceSinkDeDuplication-优化器" class="headerlink" title="ReduceSinkDeDuplication 优化器"></a>ReduceSinkDeDuplication 优化器</h4><p>ReduceSinkDeDuplication 可以合并线性相连的两个 RS。实际上 CorrelationOptimizer 是 ReduceSinkDeDuplication 的超集，能合并线性和非线性的操作 RS，但是 Hive 先实现的 ReduceSinkDeDuplication</p>
<p>譬如下面这条 SQL 语句</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from (<span class="keyword">select</span> <span class="keyword">key</span>, <span class="keyword">value</span> <span class="keyword">from</span> src <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">key</span>, <span class="keyword">value</span>) s <span class="keyword">select</span> s.key <span class="keyword">group</span> <span class="keyword">by</span> s.key;</span><br></pre></td></tr></table></figure>

<p>经过前面几个阶段之后，会生成如下的 OperatorTree，两个 Tree 是相连的，这里没有画到一起</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/67f4d79f.png" alt></p>
<p>ReduceSinkDeDuplication</p>
<p>这时候遍历 OperatorTree 后能发现前前后两个 RS 输出的 Key 值和 PartitionKey 如下</p>
<table>
<thead>
<tr>
<th align="left"></th>
<th align="left">Key</th>
<th>PartitionKey</th>
</tr>
</thead>
<tbody><tr>
<td align="left">childRS</td>
<td align="left">key</td>
<td>key</td>
</tr>
<tr>
<td align="left">parentRS</td>
<td align="left">key,value</td>
<td>key,value</td>
</tr>
</tbody></table>
<p>ReduceSinkDeDuplication 优化器检测到：1. pRS Key 完全包含 cRS Key，且排序顺序一致；2. pRS PartitionKey 完全包含 cRS PartitionKey。符合优化条件，会对执行计划进行优化。</p>
<p>ReduceSinkDeDuplication 将 childRS 和 parentheRS 与 childRS 之间的 Operator 删掉，保留的 RS 的 Key 为 key,value 字段，PartitionKey 为 key 字段。合并后的 OperatorTree 如下：</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/9ef61667.png" alt></p>
<p>ReduceSinkDeDuplication</p>
<h3 id="Phase5-OperatorTree-生成-MapReduce-Job-的过程"><a href="#Phase5-OperatorTree-生成-MapReduce-Job-的过程" class="headerlink" title="Phase5 OperatorTree 生成 MapReduce Job 的过程"></a>Phase5 OperatorTree 生成 MapReduce Job 的过程</h3><p>OperatorTree 转化为 MapReduce Job 的过程分为下面几个阶段</p>
<ol>
<li>对输出表生成 MoveTask</li>
<li>从 OperatorTree 的其中一个根节点向下深度优先遍历</li>
<li>ReduceSinkOperator 标示 Map/Reduce 的界限，多个 Job 间的界限</li>
<li>遍历其他根节点，遇过碰到 JoinOperator 合并 MapReduceTask</li>
<li>生成 StatTask 更新元数据</li>
<li>剪断 Map 与 Reduce 间的 Operator 的关系</li>
</ol>
<h4 id="对输出表生成-MoveTask"><a href="#对输出表生成-MoveTask" class="headerlink" title="对输出表生成 MoveTask"></a>对输出表生成 MoveTask</h4><p>由上一步 OperatorTree 只生成了一个 FileSinkOperator，直接生成一个 MoveTask，完成将最终生成的 HDFS 临时文件移动到目标表目录下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MoveTask[Stage-0]</span><br><span class="line">Move Operator</span><br></pre></td></tr></table></figure>

<h4 id="开始遍历"><a href="#开始遍历" class="headerlink" title="开始遍历"></a>开始遍历</h4><p>将 OperatorTree 中的所有根节点保存在一个 toWalk 的数组中，循环取出数组中的元素（省略 QB1，未画出）</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/7088b447.png" alt></p>
<p>开始遍历</p>
<p>取出最后一个元素 TS[p] 放入栈 opStack{TS[p]} 中</p>
<h4 id="Rule-1-TS-生成-MapReduceTask-对象，确定-MapWork"><a href="#Rule-1-TS-生成-MapReduceTask-对象，确定-MapWork" class="headerlink" title="Rule #1 TS% 生成 MapReduceTask 对象，确定 MapWork"></a>Rule #1 TS% 生成 MapReduceTask 对象，确定 MapWork</h4><p>发现栈中的元素符合下面规则 R1（这里用 python 代码简单表示）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == &quot;TS%&quot;</span><br></pre></td></tr></table></figure>

<p>生成一个<code>MapReduceTask[Stage-1]</code>对象，<code>MapReduceTask[Stage-1]</code>对象的<code>MapWork</code>属性保存 Operator 根节点的引用。由于 OperatorTree 之间之间的 Parent Child 关系，这个时候<code>MapReduceTask[Stage-1]</code>包含了以<code>TS[p]</code>为根的所有 Operator</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/38fce288.png" alt></p>
<p>Stage-1 生成 Map 阶段</p>
<h4 id="Rule-2-TS-RS-确定-ReduceWork"><a href="#Rule-2-TS-RS-确定-ReduceWork" class="headerlink" title="Rule #2 TS%.*RS% 确定 ReduceWork"></a>Rule #2 TS%.*RS% 确定 ReduceWork</h4><p>继续遍历 TS[p] 的子 Operator，将子 Operator 存入栈 opStack 中 当第一个 RS 进栈后，即栈 opStack = {TS[p], FIL[18], RS[4]} 时，就会满足下面的规则 R2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == &quot;TS%.*RS%&quot;</span><br></pre></td></tr></table></figure>

<p>这时候在<code>MapReduceTask[Stage-1]</code>对象的<code>ReduceWork</code>属性保存<code>JOIN[5]</code>的引用</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/f8a8803e.png" alt></p>
<p>Stage-1 生成 Reduce 阶段</p>
<h4 id="Rule-3-RS-RS-生成新-MapReduceTask-对象，切分-MapReduceTask"><a href="#Rule-3-RS-RS-生成新-MapReduceTask-对象，切分-MapReduceTask" class="headerlink" title="Rule #3 RS%.*RS% 生成新 MapReduceTask 对象，切分 MapReduceTask"></a>Rule #3 RS%.*RS% 生成新 MapReduceTask 对象，切分 MapReduceTask</h4><p>继续遍历 JOIN[5] 的子 Operator，将子 Operator 存入栈 opStack 中</p>
<p>当第二个 RS 放入栈时，即当栈<code>opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6]}</code>时，就会满足下面的规则 R3</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == “RS%.*RS%” //循环遍历opStack的每一个后缀数组</span><br></pre></td></tr></table></figure>

<p>这时候创建一个新的<code>MapReduceTask[Stage-2]</code>对象，将 OperatorTree 从<code>JOIN[5]</code>和<code>RS[6]</code>之间剪开，并为<code>JOIN[5]</code>生成一个子 Operator <code>FS[19]</code>，<code>RS[6]</code>生成一个<code>TS[20]</code>，<code>MapReduceTask[Stage-2]</code>对象的<code>MapWork</code>属性保存<code>TS[20]</code>的引用。</p>
<p>新生成的<code>FS[19]</code>将中间数据落地，存储在 HDFS 临时文件中。</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/cc1c7642.png" alt></p>
<p>Stage-2</p>
<p>继续遍历 RS[6] 的子 Operator，将子 Operator 存入栈 opStack 中</p>
<p>当<code>opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6], JOIN[8], SEL[10], GBY[12], RS[13]}</code>时，又会满足 R3 规则</p>
<p>同理生成<code>MapReduceTask[Stage-3]</code>对象，并切开 Stage-2 和 Stage-3 的 OperatorTree</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/6e876f9e.png" alt></p>
<p>Stage-3</p>
<h4 id="R4-FS-连接-MapReduceTask-与-MoveTask"><a href="#R4-FS-连接-MapReduceTask-与-MoveTask" class="headerlink" title="R4 FS% 连接 MapReduceTask 与 MoveTask"></a>R4 FS% 连接 MapReduceTask 与 MoveTask</h4><p>最终将所有子 Operator 存入栈中之后，<code>opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6], JOIN[8], SEL[10], GBY[12], RS[13], GBY[14], SEL[15], FS[17]}</code> 满足规则 R4</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;.join([t + &quot;%&quot; for t in opStack]) == “FS%”</span><br></pre></td></tr></table></figure>

<p>这时候将<code>MoveTask</code>与<code>MapReduceTask[Stage-3]</code>连接起来，并生成一个<code>StatsTask</code>，修改表的元信息</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/6d3b67c9.png" alt></p>
<p>MoveTask</p>
<h4 id="合并-Stage"><a href="#合并-Stage" class="headerlink" title="合并 Stage"></a>合并 Stage</h4><p>此时并没有结束，还有两个根节点没有遍历。</p>
<p>将 opStack 栈清空，将 toWalk 的第二个元素加入栈。会发现<code>opStack = {TS[du]}</code>继续满足 R1 TS%，生成<code>MapReduceTask[Stage-5]</code></p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/6799e54e.png" alt></p>
<p>Stage-5</p>
<p>继续从<code>TS[du]</code>向下遍历，当<code>opStack={TS[du], RS[7]}</code>时，满足规则 R2 TS%.*RS%</p>
<p>此时将<code>JOIN[8]</code>保存为<code>MapReduceTask[Stage-5]</code>的<code>ReduceWork</code>时，发现在一个 Map 对象保存的 Operator 与 MapReduceWork 对象关系的<code>Map&lt;Operator, MapReduceWork&gt;</code>对象中发现，<code>JOIN[8]</code>已经存在。此时将<code>MapReduceTask[Stage-2]</code>和<code>MapReduceTask[Stage-5]</code>合并为一个 MapReduceTask</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/164ea8fd.png" alt></p>
<p>合并 Stage-2 和 Stage-5</p>
<p>同理从最后一个根节点<code>TS[c]</code>开始遍历，也会对 MapReduceTask 进行合并</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/9259eee5.png" alt></p>
<p>合并 Stage-1 和 Stage-6</p>
<h4 id="切分-Map-Reduce-阶段"><a href="#切分-Map-Reduce-阶段" class="headerlink" title="切分 Map Reduce 阶段"></a>切分 Map Reduce 阶段</h4><p>最后一个阶段，将 MapWork 和 ReduceWork 中的 OperatorTree 以 RS 为界限剪开</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/129684ea.png" alt></p>
<p>切分 Map Reduce 阶段</p>
<h4 id="OperatorTree-生成-MapReduceTask-全貌"><a href="#OperatorTree-生成-MapReduceTask-全貌" class="headerlink" title="OperatorTree 生成 MapReduceTask 全貌"></a>OperatorTree 生成 MapReduceTask 全貌</h4><p>最终共生成 3 个 MapReduceTask，如下图</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/13308564.png" alt></p>
<p>OperatorTree 生成 MapReduceTask 全貌</p>
<h3 id="Phase6-物理层优化器"><a href="#Phase6-物理层优化器" class="headerlink" title="Phase6 物理层优化器"></a>Phase6 物理层优化器</h3><p>这里不详细介绍每个优化器的原理，单独介绍一下 MapJoin 的优化器</p>
<table>
<thead>
<tr>
<th align="left">名称</th>
<th align="left">作用</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Vectorizer</td>
<td align="left">HIVE-4160，将在0.13中发布</td>
</tr>
<tr>
<td align="left">SortMergeJoinResolver</td>
<td align="left">与bucket配合，类似于归并排序</td>
</tr>
<tr>
<td align="left">SamplingOptimizer</td>
<td align="left">并行order by优化器，在0.12中发布</td>
</tr>
<tr>
<td align="left">CommonJoinResolver + MapJoinResolver</td>
<td align="left">MapJoin优化器</td>
</tr>
</tbody></table>
<h4 id="MapJoin-原理"><a href="#MapJoin-原理" class="headerlink" title="MapJoin 原理"></a>MapJoin 原理</h4><p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/a4cd80c9.png" alt></p>
<p>mapjoin 原理</p>
<p>MapJoin 简单说就是在 Map 阶段将小表读入内存，顺序扫描大表完成 Join。</p>
<p>上图是 Hive MapJoin 的原理图，出自 Facebook 工程师 Liyin Tang 的一篇介绍 Join 优化的 slice，从图中可以看出 MapJoin 分为两个阶段：</p>
<ol>
<li><p>通过 MapReduce Local Task，将小表读入内存，生成 HashTableFiles 上传至 Distributed Cache 中，这里会对 HashTableFiles 进行压缩。</p>
</li>
<li><p>MapReduce Job 在 Map 阶段，每个 Mapper 从 Distributed Cache 读取 HashTableFiles 到内存中，顺序扫描大表，在 Map 阶段直接进行 Join，将数据传递给下一个 MapReduce 任务。</p>
</li>
</ol>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/678dfd68.png" alt></p>
<p>conditionaltask</p>
<p>如果 Join 的两张表一张表是临时表，就会生成一个 ConditionalTask，在运行期间判断是否使用 MapJoin</p>
<h4 id="CommonJoinResolver-优化器"><a href="#CommonJoinResolver-优化器" class="headerlink" title="CommonJoinResolver 优化器"></a>CommonJoinResolver 优化器</h4><p>CommonJoinResolver 优化器就是将 CommonJoin 转化为 MapJoin，转化过程如下</p>
<ol>
<li>深度优先遍历 Task Tree</li>
<li>找到 JoinOperator，判断左右表数据量大小</li>
<li>对与小表 + 大表 =&gt; MapJoinTask，对于小 / 大表 + 中间表 =&gt; ConditionalTask</li>
</ol>
<p>遍历上一个阶段生成的 MapReduce 任务，发现<code>MapReduceTask[Stage-2]</code> <code>JOIN[8]</code>中有一张表为临时表，先对 Stage-2 进行深度拷贝（由于需要保留原始执行计划为 Backup Plan，所以这里将执行计划拷贝了一份），生成一个 MapJoinOperator 替代 JoinOperator，然后生成一个 MapReduceLocalWork 读取小表生成 HashTableFiles 上传至 DistributedCache 中。</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/4e209569.png" alt></p>
<p>mapjoin 变换</p>
<p>MapReduceTask 经过变换后的执行计划如下图所示</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/136eb26d.png" alt></p>
<p>mapjoin 变换</p>
<h4 id="MapJoinResolver-优化器"><a href="#MapJoinResolver-优化器" class="headerlink" title="MapJoinResolver 优化器"></a>MapJoinResolver 优化器</h4><p>MapJoinResolver 优化器遍历 Task Tree，将所有有 local work 的 MapReduceTask 拆成两个 Task</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/1278f2fa.png" alt></p>
<p>MapJoinResolver</p>
<p>最终 MapJoinResolver 处理完之后，执行计划如下图所示</p>
<p><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/2a6ea0e2.png" alt></p>
<p>MapJoinResolver</p>
<h3 id="Hive-SQL-编译过程的设计"><a href="#Hive-SQL-编译过程的设计" class="headerlink" title="Hive SQL 编译过程的设计"></a>Hive SQL 编译过程的设计</h3><p>从上述整个 SQL 编译的过程，可以看出编译过程的设计有几个优点值得学习和借鉴</p>
<ul>
<li>使用 Antlr 开源软件定义语法规则，大大简化了词法和语法的编译解析过程，仅仅需要维护一份语法文件即可。</li>
<li>整体思路很清晰，分阶段的设计使整个编译过程代码容易维护，使得后续各种优化器方便的以可插拔的方式开关，譬如 Hive 0.13 最新的特性 Vectorization 和对 Tez 引擎的支持都是可插拔的。</li>
<li>每个 Operator 只完成单一的功能，简化了整个 MapReduce 程序。</li>
</ul>
<h3 id="社区发展方向"><a href="#社区发展方向" class="headerlink" title="社区发展方向"></a>社区发展方向</h3><p>Hive 依然在迅速的发展中，为了提升 Hive 的性能，hortonworks 公司主导的 Stinger 计划提出了一系列对 Hive 的改进，比较重要的改进有：</p>
<ul>
<li>Vectorization - 使 Hive 从单行单行处理数据改为批量处理方式，大大提升了指令流水线和缓存的利用率</li>
<li>Hive on Tez - 将 Hive 底层的 MapReduce 计算框架替换为 Tez 计算框架。Tez 不仅可以支持多 Reduce 阶段的任务 MRR，还可以一次性提交执行计划，因而能更好的分配资源。</li>
<li>Cost Based Optimizer - 使 Hive 能够自动选择最优的 Join 顺序，提高查询速度</li>
<li>Implement insert, update, and delete in Hive with full ACID support - 支持表按主键的增量更新</li>
</ul>
<p>我们也将跟进社区的发展，结合自身的业务需要，提升 Hive 型 ETL 流程的性能</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>Antlr: <a href="http://www.antlr.org/" target="_blank" rel="noopener">http://www.antlr.org/</a> </p>
<p>Wiki Antlr 介绍: <a href="http://en.wikipedia.org/wiki/ANTLR" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/ANTLR</a> </p>
<p>Hive Wiki: <a href="https://cwiki.apache.org/confluence/display/Hive/Home" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/Home</a> </p>
<p>HiveSQL 编译过程: <a href="http://www.slideshare.net/recruitcojp/internal-hive" target="_blank" rel="noopener">http://www.slideshare.net/recruitcojp/internal-hive</a> </p>
<p>Join Optimization in Hive: <a href="https://cwiki.apache.org/confluence/download/attachments/27362054/Hive+Summit+2011-join.pdf?version=1&modificationDate=1309986642000" target="_blank" rel="noopener">Join Strategies in Hive from the 2011 Hadoop Summit (Liyin Tang, Namit Jain)</a> Hive Design Docs: <a href="https://cwiki.apache.org/confluence/display/Hive/DesignDocs" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/DesignDocs</a></p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/sql/" rel="tag"># sql</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/07/09/Hive/join/" rel="next" title="Hive中Join的类型和用法">
                <i class="fa fa-chevron-left"></i> Hive中Join的类型和用法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">WHJason</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                    <span class="site-state-item-count">1</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                    <span class="site-state-item-count">1</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/gofreehj" title="GitHub &rarr; https://github.com/gofreehj" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:gofreehj@163.com" title="E-Mail &rarr; mailto:gofreehj@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce-实现基本-SQL-操作的原理"><span class="nav-number">1.</span> <span class="nav-text">MapReduce 实现基本 SQL 操作的原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Join-的实现原理"><span class="nav-number">1.1.</span> <span class="nav-text">Join 的实现原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Group-By-的实现原理"><span class="nav-number">1.2.</span> <span class="nav-text">Group By 的实现原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distinct-的实现原理"><span class="nav-number">1.3.</span> <span class="nav-text">Distinct 的实现原理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SQL-转化为-MapReduce-的过程"><span class="nav-number">2.</span> <span class="nav-text">SQL 转化为 MapReduce 的过程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Phase1-SQL-词法，语法解析"><span class="nav-number">2.1.</span> <span class="nav-text">Phase1 SQL 词法，语法解析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Antlr"><span class="nav-number">2.1.1.</span> <span class="nav-text">Antlr</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#抽象语法树-AST-Tree"><span class="nav-number">2.1.2.</span> <span class="nav-text">抽象语法树 AST Tree</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#样例-SQL"><span class="nav-number">2.1.3.</span> <span class="nav-text">样例 SQL</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SQL-生成-AST-Tree"><span class="nav-number">2.1.4.</span> <span class="nav-text">SQL 生成 AST Tree</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Phase2-SQL-基本组成单元-QueryBlock"><span class="nav-number">2.2.</span> <span class="nav-text">Phase2 SQL 基本组成单元 QueryBlock</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#QueryBlock"><span class="nav-number">2.2.1.</span> <span class="nav-text">QueryBlock</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AST-Tree-生成-QueryBlock"><span class="nav-number">2.2.2.</span> <span class="nav-text">AST Tree 生成 QueryBlock</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Phase3-逻辑操作符-Operator"><span class="nav-number">2.3.</span> <span class="nav-text">Phase3 逻辑操作符 Operator</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Operator"><span class="nav-number">2.3.1.</span> <span class="nav-text">Operator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#QueryBlock-生成-Operator-Tree"><span class="nav-number">2.3.2.</span> <span class="nav-text">QueryBlock 生成 Operator Tree</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Phase4-逻辑层优化器"><span class="nav-number">2.4.</span> <span class="nav-text">Phase4 逻辑层优化器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#PredicatePushDown-优化器"><span class="nav-number">2.4.1.</span> <span class="nav-text">PredicatePushDown 优化器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NonBlockingOpDeDupProc-优化器"><span class="nav-number">2.4.2.</span> <span class="nav-text">NonBlockingOpDeDupProc 优化器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ReduceSinkDeDuplication-优化器"><span class="nav-number">2.4.3.</span> <span class="nav-text">ReduceSinkDeDuplication 优化器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Phase5-OperatorTree-生成-MapReduce-Job-的过程"><span class="nav-number">2.5.</span> <span class="nav-text">Phase5 OperatorTree 生成 MapReduce Job 的过程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#对输出表生成-MoveTask"><span class="nav-number">2.5.1.</span> <span class="nav-text">对输出表生成 MoveTask</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#开始遍历"><span class="nav-number">2.5.2.</span> <span class="nav-text">开始遍历</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Rule-1-TS-生成-MapReduceTask-对象，确定-MapWork"><span class="nav-number">2.5.3.</span> <span class="nav-text">Rule #1 TS% 生成 MapReduceTask 对象，确定 MapWork</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Rule-2-TS-RS-确定-ReduceWork"><span class="nav-number">2.5.4.</span> <span class="nav-text">Rule #2 TS%.*RS% 确定 ReduceWork</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Rule-3-RS-RS-生成新-MapReduceTask-对象，切分-MapReduceTask"><span class="nav-number">2.5.5.</span> <span class="nav-text">Rule #3 RS%.*RS% 生成新 MapReduceTask 对象，切分 MapReduceTask</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#R4-FS-连接-MapReduceTask-与-MoveTask"><span class="nav-number">2.5.6.</span> <span class="nav-text">R4 FS% 连接 MapReduceTask 与 MoveTask</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#合并-Stage"><span class="nav-number">2.5.7.</span> <span class="nav-text">合并 Stage</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#切分-Map-Reduce-阶段"><span class="nav-number">2.5.8.</span> <span class="nav-text">切分 Map Reduce 阶段</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#OperatorTree-生成-MapReduceTask-全貌"><span class="nav-number">2.5.9.</span> <span class="nav-text">OperatorTree 生成 MapReduceTask 全貌</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Phase6-物理层优化器"><span class="nav-number">2.6.</span> <span class="nav-text">Phase6 物理层优化器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MapJoin-原理"><span class="nav-number">2.6.1.</span> <span class="nav-text">MapJoin 原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CommonJoinResolver-优化器"><span class="nav-number">2.6.2.</span> <span class="nav-text">CommonJoinResolver 优化器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapJoinResolver-优化器"><span class="nav-number">2.6.3.</span> <span class="nav-text">MapJoinResolver 优化器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-SQL-编译过程的设计"><span class="nav-number">2.7.</span> <span class="nav-text">Hive SQL 编译过程的设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#社区发展方向"><span class="nav-number">2.8.</span> <span class="nav-text">社区发展方向</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参考"><span class="nav-number">2.9.</span> <span class="nav-text">参考</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WHJason</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>



  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  


  <script src="/js/next-boot.js?v=7.2.0"></script>


  

  

  

  


  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  
  
  <script>
    
    function addCount(Counter) {
      var $visitors = $('.leancloud_visitors');
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
            Counter('put', '/classes/Counter/' + counter.objectId, JSON.stringify({ time: { '__op': 'Increment', 'amount': 1 } }))
            
              .done(function() {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.time + 1);
              })
            
              .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
              })
          } else {
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text('Counter not initialized! More info at console err msg.');
              console.error('ATTENTION! LeanCloud counter has security bug, see how to solve it here: https://github.com/theme-next/hexo-leancloud-counter-security. \n However, you can still use LeanCloud without security, by setting `security` option to `false`.');
            
          }
        })
        .fail(function ({ responseJSON }) {
          console.log('LeanCloud Counter Error: ' + responseJSON.code + ' ' + responseJSON.error);
        });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + 'bzjPPVRfRtfwsArhsxdPgDmk-gzGzoHsz')
        .done(function({ api_server }) {
          var Counter = function(method, url, data) {
            return $.ajax({
              method: method,
              url: 'https://' + api_server + '/1.1' + url,
              headers: {
                'X-LC-Id': 'bzjPPVRfRtfwsArhsxdPgDmk-gzGzoHsz',
                'X-LC-Key': 'g6ccF1TQOytc2mep3ufPX416',
                'Content-Type': 'application/json',
              },
              data: data
            });
          };
          
            const localhost = /http:\/\/(localhost|127.0.0.1|0.0.0.0)/;
            if (localhost.test(document.URL)) return;
            addCount(Counter);
          
        });
    });
  </script>



  

  
  

  
  

  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
